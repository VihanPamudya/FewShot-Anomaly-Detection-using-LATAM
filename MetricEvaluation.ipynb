{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-01 21:06:35.157651: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-09-01 21:06:35.157690: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold, KFold\n",
    "from sklearn import linear_model, metrics, preprocessing\n",
    "from math import sqrt, floor\n",
    "from datetime import datetime, timedelta\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, BatchNormalization, Input, LSTM,Dense,RepeatVector, TimeDistributed , LeakyReLU\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, IsolationForest\n",
    "from sklearn.metrics import r2_score, make_scorer, accuracy_score, mean_squared_error, mean_absolute_error\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl\n",
    "import tensorflow as tf\n",
    "LeakyReLU = LeakyReLU(alpha=0.1)\n",
    "import warnings\n",
    "import pandas as pd\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "import time\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "import math\n",
    "from sklearn.decomposition import PCA\n",
    "from numpy import array\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import keras\n",
    "from keras.layers import Dense, Dropout, Activation, BatchNormalization, Input,Conv2D, Conv1D, Conv1DTranspose,MaxPooling1D\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras import optimizers, Sequential\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from statistics import mean\n",
    "from sklearn.metrics import f1_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.metrics import f1_score, accuracy_score,precision_score, recall_score\n",
    "def getScore(df):\n",
    "    # print(df)\n",
    "    return [f1_score(y_true=df['ytrue'], y_pred=df['ypred_mse'])]\n",
    "def getDf(channel, path, dayRange):\n",
    "#     print(dayRange)\n",
    "    ae_df, convae_df, lstmae_df, lstm_attnae_df, tcnae_df = pd.DataFrame(), pd.DataFrame(),pd.DataFrame(),pd.DataFrame(), pd.DataFrame()\n",
    "    files = os.listdir(path)\n",
    "#     print(files)\n",
    "    if '.ipynb_checkpoints' in files:\n",
    "        files.remove('.ipynb_checkpoints')\n",
    "    for file in files:\n",
    "        with open(f'{path}{file}', 'rb') as f:\n",
    "                    if 'STL_ConvAE' in file:\n",
    "                        df_dict = pickle.load(f)\n",
    "#                         print(df_dict)\n",
    "                        convae_df = df_dict[dayRange][channel]\n",
    "                        convae_df = convae_df.dropna()\n",
    "                    elif 'STL_LstmAE' in file:\n",
    "                        df_dict = pickle.load(f)\n",
    "                        lstmae_df = df_dict[dayRange][channel]\n",
    "                        lstmae_df = lstmae_df.dropna()\n",
    "                    elif 'STL_TcnAE' in file:\n",
    "                        df_dict = pickle.load(f)\n",
    "                        tcnae_df = df_dict[dayRange][channel]\n",
    "                        tcnae_df = tcnae_df.dropna()\n",
    "                    elif 'STL_LstmAttnAE' in file:\n",
    "                        df_dict = pickle.load(f)\n",
    "                        lstm_attnae_df = df_dict[dayRange][channel]\n",
    "                        lstm_attnae_df = lstm_attnae_df.dropna()\n",
    "                    elif 'STL_AE' in file:\n",
    "                        df_dict = pickle.load(f)\n",
    "                        ae_df = df_dict[dayRange][channel]\n",
    "                        ae_df= ae_df.dropna()\n",
    "    return ae_df, convae_df, lstmae_df, lstm_attnae_df, tcnae_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDynamicThreshold(df, tail=100, w_y=0.3, w_z=0.7):\n",
    "    train_mean = df['mse_scores'].mean()\n",
    "    train_std = df['mse_scores'].std()\n",
    "    df = df.tail(tail)\n",
    "    tail_mean = df['mse_scores'].mean()\n",
    "    tail_std = df['mse_scores'].std()\n",
    "    threshold = w_y*(train_mean+train_std)+w_z*(tail_mean+tail_std)\n",
    "    return threshold\n",
    "def getthreshold(df_train, df_test):\n",
    "    df_tr = df_train[['ytrue', 'mse_scores']]\n",
    "    df_te = df_test[['ytrue', 'mse_scores']]\n",
    "    thresholds=[]\n",
    "    for i in range(df_test.shape[0]):\n",
    "        df_tr = pd.concat([df_tr, df_te[i:i+1]], axis = 0)\n",
    "        thresholds.append(getDynamicThreshold(df_tr,  w_y=0.4, w_z=0.6))\n",
    "#         thresholds.append(getDynamicThreshold(df_tr))\n",
    "    \n",
    "    df_test['thresholds'] = thresholds\n",
    "#     df_test['thresholds'] = getDynamicThreshold(df_tr,  w_y=0.5, w_z=0.5)\n",
    "    return df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataFrames(channel, itr, dayRange):\n",
    "    train_path = f'datapath'\n",
    "    test_path = f'datapath'\n",
    "    ae_df_train, convae_df_train, lstmae_df_train, lstm_attnae_df_train, tcnae_df_train = getDf(channel, train_path, dayRange)\n",
    "    ae_df_test, convae_df_test, lstmae_df_test, lstm_attnae_df_test,tcnae_df_test = getDf(channel, test_path, dayRange)\n",
    "#     print(ae_df_test.shape, convae_df_test.shape, lstmae_df_test.shape, lstm_attnae_df_test.shape, tcnae_df_test.shape)\n",
    "    ae_df  = getthreshold(ae_df_train, ae_df_test)\n",
    "    convae_df = getthreshold(convae_df_train, convae_df_test)\n",
    "    lstmae_df = getthreshold(lstmae_df_train, lstmae_df_test)\n",
    "    lstm_attnae_df = getthreshold(lstm_attnae_df_train, lstm_attnae_df_test)\n",
    "    \n",
    "    tcnae_df = getthreshold(tcnae_df_train, tcnae_df_test)\n",
    "   \n",
    "    return  ae_df, convae_df, lstmae_df, lstm_attnae_df, tcnae_df\n",
    "#     return ae_df_test, convae_df_test, lstmae_df_test, lstm_attnae_df_test,tcnae_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDfLearn(metric, itr, dayRange):\n",
    "    df_learn = pd.DataFrame()\n",
    "    for i in range(19):\n",
    "        channel = f'inv_{i}'\n",
    "        ae_df, convae_df, lstmae_df, lstm_attnae_df, tcnae_df = getDataFrames(channel, itr, dayRange)\n",
    "        \n",
    "        df_learn = pd.concat([df_learn,pd.DataFrame({'file':channel,'ae':getScore(ae_df,metric,channel,'ae'),'convae':getScore(convae_df,metric,channel,'convae'),\n",
    "            'tcnae':getScore(tcnae_df, metric, channel, 'tcnae'),'lstmae':getScore(lstmae_df,metric,channel,'lstmae'), \n",
    "                                    'lstm_attnae':getScore(lstm_attnae_df,metric,channel, 'lstm_attnae')})], axis=0)\n",
    "    \n",
    "    df_learn = df_learn.set_index(df_learn['file'])\n",
    "    df_learn = df_learn.drop(columns=['file'])\n",
    "    return df_learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rec\n",
      "                    0         0         0\n",
      "ae           0.748058  0.694276  0.692049\n",
      "convae       0.750525  0.693784  0.701674\n",
      "tcnae        0.778615  0.764932  0.724389\n",
      "lstmae       0.733916  0.636777  0.557720\n",
      "lstm_attnae  0.746884  0.699152  0.724796\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def getScore(df,metric, channel,name_dataframe ):\n",
    "#     print(name_dataframe)\n",
    "    if name_dataframe=='isofor' or name_dataframe=='mtl_isofor':\n",
    "        df['ypred'] = df['ypred_mse']\n",
    "    else:\n",
    "        df['ypred'] = np.where(df['mse_scores']>df['thresholds'],1,0)\n",
    "#         df['ypred'] = df['ypred_mse']\n",
    "    if metric == 'f1':\n",
    "        return [f1_score(y_true=df['ytrue'], y_pred=df['ypred'])]    \n",
    "    if metric == 'acc':\n",
    "        return [accuracy_score(y_true=df['ytrue'], y_pred=df['ypred'])]\n",
    "    if metric == 'prec':\n",
    "        return [precision_score(y_true=df['ytrue'], y_pred=df['ypred'])]\n",
    "    if metric == 'rec':\n",
    "        return [recall_score(y_true=df['ytrue'], y_pred=df['ypred'])]\n",
    "df_metric = pd.DataFrame()\n",
    "df_zsl_metric = pd.DataFrame()\n",
    "df_source_metric = pd.DataFrame()\n",
    "for metric in ['rec']:\n",
    "    print(metric)\n",
    "    df = pd.DataFrame()\n",
    "    for daysRange in [14, 30, 90]:\n",
    "        df_learn1 = getDfLearn(metric, 1, daysRange)\n",
    "\n",
    "        df_learn2 = getDfLearn(metric, 2, daysRange)\n",
    "        df_learn3 = getDfLearn(metric, 3, daysRange)\n",
    "\n",
    "        df_learn = (df_learn1 + df_learn2 + df_learn3)/3\n",
    "\n",
    "        df = pd.concat([df,df_learn.mean()], axis=1)\n",
    "    df_metric = pd.concat([df_metric,df], axis=1)\n",
    "    print(df_metric)\n",
    "    \n",
    "                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metric.to_csv('./MaxThresholding.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metric.to_csv('./dynamicThresholding0505.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metric.to_csv('./FloatingdynamicThresholding0406.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/mnt/stud/home/vpulagura/experiment/OpenDatasets/SWaT/data/SWaTNormal.csv')\n",
    "df['Timestamp'] = pd.to_datetime(df[' Timestamp'])\n",
    "df = df.set_index(df['Timestamp'])\n",
    "df = df.drop(columns=['Timestamp',' Timestamp'])\n",
    "df['Normal/Attack'] = np.where(df['Normal/Attack'] == 'Normal',0,1)\n",
    "df_down = df.resample('0.5T').mean()\n",
    "df_down =  df_down.drop_duplicates()\n",
    "df_down = df_down.dropna()\n",
    "df_down.to_csv('/mnt/stud/home/vpulagura/experiment/OpenDatasets/SWaT/data/DownsampledNormal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(495000, 53)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/mnt/stud/home/vpulagura/experiment/OpenDatasets/SWaT/data/SWaTNormal.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(395298, 53)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/mnt/stud/home/vpulagura/experiment/OpenDatasets/SWaT/data/SWaTAttack.csv')\n",
    "df[df['Normal/Attack'] == 'Normal'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/mnt/stud/home/vpulagura/experiment/OpenDatasets/SWaT/data/SWaTAttack.csv')\n",
    "df['Timestamp'] = pd.to_datetime(df[' Timestamp'])\n",
    "df = df.set_index(df['Timestamp'])\n",
    "df = df.drop(columns=['Timestamp',' Timestamp'])\n",
    "df['Normal/Attack'] = np.where(df['Normal/Attack'] == 'Normal',0,1)\n",
    "df_down = df.resample('0.5T').mean()\n",
    "df_down =  df_down.drop_duplicates()\n",
    "df_down = df_down.dropna()\n",
    "df_down['Normal/Attack'] = np.where(df_down['Normal/Attack']>0,1,0)\n",
    "df_down.to_csv('/mnt/stud/home/vpulagura/experiment/OpenDatasets/SWaT/data/DownsampledAttack.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>FIT101</th>\n",
       "      <th>LIT101</th>\n",
       "      <th>MV101</th>\n",
       "      <th>P101</th>\n",
       "      <th>P102</th>\n",
       "      <th>AIT201</th>\n",
       "      <th>AIT202</th>\n",
       "      <th>AIT203</th>\n",
       "      <th>FIT201</th>\n",
       "      <th>MV201</th>\n",
       "      <th>P201</th>\n",
       "      <th>P202</th>\n",
       "      <th>P203</th>\n",
       "      <th>P204</th>\n",
       "      <th>P205</th>\n",
       "      <th>P206</th>\n",
       "      <th>DPIT301</th>\n",
       "      <th>FIT301</th>\n",
       "      <th>LIT301</th>\n",
       "      <th>MV301</th>\n",
       "      <th>MV302</th>\n",
       "      <th>MV303</th>\n",
       "      <th>MV304</th>\n",
       "      <th>P301</th>\n",
       "      <th>P302</th>\n",
       "      <th>AIT401</th>\n",
       "      <th>AIT402</th>\n",
       "      <th>FIT401</th>\n",
       "      <th>LIT401</th>\n",
       "      <th>P401</th>\n",
       "      <th>P402</th>\n",
       "      <th>P403</th>\n",
       "      <th>P404</th>\n",
       "      <th>UV401</th>\n",
       "      <th>AIT501</th>\n",
       "      <th>AIT502</th>\n",
       "      <th>AIT503</th>\n",
       "      <th>AIT504</th>\n",
       "      <th>FIT501</th>\n",
       "      <th>FIT502</th>\n",
       "      <th>FIT503</th>\n",
       "      <th>FIT504</th>\n",
       "      <th>P501</th>\n",
       "      <th>P502</th>\n",
       "      <th>PIT501</th>\n",
       "      <th>PIT502</th>\n",
       "      <th>PIT503</th>\n",
       "      <th>FIT601</th>\n",
       "      <th>P601</th>\n",
       "      <th>P602</th>\n",
       "      <th>P603</th>\n",
       "      <th>Normal/Attack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-12-22 16:30:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>124.096297</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>251.922600</td>\n",
       "      <td>8.311000</td>\n",
       "      <td>312.832623</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.560983</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>138.001473</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>169.238700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>133.551660</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.445559</td>\n",
       "      <td>175.396040</td>\n",
       "      <td>260.702400</td>\n",
       "      <td>123.347827</td>\n",
       "      <td>0.001538</td>\n",
       "      <td>0.001409</td>\n",
       "      <td>0.001664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.100231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.348500</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-12-22 16:30:30</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>124.220587</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>251.922600</td>\n",
       "      <td>8.309002</td>\n",
       "      <td>313.035133</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.560983</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>137.997463</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>169.336927</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>132.621120</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.444096</td>\n",
       "      <td>175.421673</td>\n",
       "      <td>260.702400</td>\n",
       "      <td>123.415783</td>\n",
       "      <td>0.001538</td>\n",
       "      <td>0.001409</td>\n",
       "      <td>0.001664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.058041</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.348500</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-12-22 16:31:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>124.029560</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>251.922600</td>\n",
       "      <td>8.309986</td>\n",
       "      <td>313.201733</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.560983</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>137.650337</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>169.533480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>133.238917</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.444544</td>\n",
       "      <td>175.603710</td>\n",
       "      <td>260.702400</td>\n",
       "      <td>123.379893</td>\n",
       "      <td>0.001538</td>\n",
       "      <td>0.001409</td>\n",
       "      <td>0.001664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.068188</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.348500</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-12-22 16:31:30</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>123.787493</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>251.922600</td>\n",
       "      <td>8.309515</td>\n",
       "      <td>313.391437</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.562371</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>137.475430</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>169.596697</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>132.054613</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.444737</td>\n",
       "      <td>175.660953</td>\n",
       "      <td>260.702400</td>\n",
       "      <td>123.314500</td>\n",
       "      <td>0.001538</td>\n",
       "      <td>0.001409</td>\n",
       "      <td>0.001664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.068188</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.348500</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-12-22 16:32:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>123.383193</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>251.922600</td>\n",
       "      <td>8.310445</td>\n",
       "      <td>313.572593</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.564185</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>136.323223</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>169.597557</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>132.162273</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.443733</td>\n",
       "      <td>175.698533</td>\n",
       "      <td>260.747270</td>\n",
       "      <td>123.338877</td>\n",
       "      <td>0.001538</td>\n",
       "      <td>0.001409</td>\n",
       "      <td>0.001664</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.068188</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.313787</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16495</th>\n",
       "      <td>2015-12-28 09:57:30</td>\n",
       "      <td>2.556886</td>\n",
       "      <td>520.460163</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>262.117613</td>\n",
       "      <td>8.392004</td>\n",
       "      <td>328.743903</td>\n",
       "      <td>2.441782</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.697378</td>\n",
       "      <td>2.210396</td>\n",
       "      <td>948.864637</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>148.808</td>\n",
       "      <td>155.853213</td>\n",
       "      <td>1.716268</td>\n",
       "      <td>932.355810</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.876250</td>\n",
       "      <td>144.885900</td>\n",
       "      <td>264.842373</td>\n",
       "      <td>12.266090</td>\n",
       "      <td>1.726062</td>\n",
       "      <td>1.282836</td>\n",
       "      <td>0.735563</td>\n",
       "      <td>0.307807</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>251.054733</td>\n",
       "      <td>1.674516</td>\n",
       "      <td>189.845550</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16496</th>\n",
       "      <td>2015-12-28 09:58:00</td>\n",
       "      <td>2.544246</td>\n",
       "      <td>519.901473</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>261.994780</td>\n",
       "      <td>8.395080</td>\n",
       "      <td>328.728520</td>\n",
       "      <td>2.442059</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.694819</td>\n",
       "      <td>2.210802</td>\n",
       "      <td>950.720453</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>148.808</td>\n",
       "      <td>156.020690</td>\n",
       "      <td>1.717562</td>\n",
       "      <td>934.082277</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.877019</td>\n",
       "      <td>144.926100</td>\n",
       "      <td>264.855180</td>\n",
       "      <td>12.180211</td>\n",
       "      <td>1.728326</td>\n",
       "      <td>1.287610</td>\n",
       "      <td>0.735397</td>\n",
       "      <td>0.306763</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>251.252893</td>\n",
       "      <td>1.667574</td>\n",
       "      <td>189.996673</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16497</th>\n",
       "      <td>2015-12-28 09:58:30</td>\n",
       "      <td>2.546317</td>\n",
       "      <td>521.215133</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>261.984100</td>\n",
       "      <td>8.392432</td>\n",
       "      <td>328.685000</td>\n",
       "      <td>2.442764</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.651174</td>\n",
       "      <td>2.209111</td>\n",
       "      <td>952.979500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>148.808</td>\n",
       "      <td>156.165107</td>\n",
       "      <td>1.717417</td>\n",
       "      <td>938.164577</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.876314</td>\n",
       "      <td>144.916727</td>\n",
       "      <td>264.778260</td>\n",
       "      <td>12.090490</td>\n",
       "      <td>1.728143</td>\n",
       "      <td>1.287204</td>\n",
       "      <td>0.735781</td>\n",
       "      <td>0.307876</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>251.173293</td>\n",
       "      <td>1.681991</td>\n",
       "      <td>189.921897</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16498</th>\n",
       "      <td>2015-12-28 09:59:00</td>\n",
       "      <td>2.540616</td>\n",
       "      <td>522.947487</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>262.005433</td>\n",
       "      <td>8.390680</td>\n",
       "      <td>328.567070</td>\n",
       "      <td>2.442059</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.687561</td>\n",
       "      <td>2.210276</td>\n",
       "      <td>953.821950</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>148.808</td>\n",
       "      <td>155.938637</td>\n",
       "      <td>1.718258</td>\n",
       "      <td>940.933093</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.876058</td>\n",
       "      <td>145.100373</td>\n",
       "      <td>264.630830</td>\n",
       "      <td>12.105872</td>\n",
       "      <td>1.728356</td>\n",
       "      <td>1.281841</td>\n",
       "      <td>0.735269</td>\n",
       "      <td>0.307171</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>251.176520</td>\n",
       "      <td>1.704418</td>\n",
       "      <td>189.868497</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16499</th>\n",
       "      <td>2015-12-28 09:59:30</td>\n",
       "      <td>2.533933</td>\n",
       "      <td>521.912513</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>262.016100</td>\n",
       "      <td>8.391715</td>\n",
       "      <td>328.620853</td>\n",
       "      <td>2.442260</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.728429</td>\n",
       "      <td>2.209965</td>\n",
       "      <td>955.096997</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>148.808</td>\n",
       "      <td>156.030080</td>\n",
       "      <td>1.717135</td>\n",
       "      <td>941.793140</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.877820</td>\n",
       "      <td>145.167013</td>\n",
       "      <td>264.547500</td>\n",
       "      <td>12.149452</td>\n",
       "      <td>1.726335</td>\n",
       "      <td>1.283814</td>\n",
       "      <td>0.735512</td>\n",
       "      <td>0.307436</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>251.078753</td>\n",
       "      <td>1.687865</td>\n",
       "      <td>189.840737</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16500 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Timestamp    FIT101      LIT101  MV101  P101  P102  \\\n",
       "0      2015-12-22 16:30:00  0.000000  124.096297    1.0   1.0   1.0   \n",
       "1      2015-12-22 16:30:30  0.000000  124.220587    1.0   1.0   1.0   \n",
       "2      2015-12-22 16:31:00  0.000000  124.029560    1.0   1.0   1.0   \n",
       "3      2015-12-22 16:31:30  0.000032  123.787493    1.0   1.0   1.0   \n",
       "4      2015-12-22 16:32:00  0.000000  123.383193    1.0   1.0   1.0   \n",
       "...                    ...       ...         ...    ...   ...   ...   \n",
       "16495  2015-12-28 09:57:30  2.556886  520.460163    2.0   2.0   1.0   \n",
       "16496  2015-12-28 09:58:00  2.544246  519.901473    2.0   2.0   1.0   \n",
       "16497  2015-12-28 09:58:30  2.546317  521.215133    2.0   2.0   1.0   \n",
       "16498  2015-12-28 09:59:00  2.540616  522.947487    2.0   2.0   1.0   \n",
       "16499  2015-12-28 09:59:30  2.533933  521.912513    2.0   2.0   1.0   \n",
       "\n",
       "           AIT201    AIT202      AIT203    FIT201  MV201  P201  P202  P203  \\\n",
       "0      251.922600  8.311000  312.832623  0.000000    1.0   1.0   1.0   1.0   \n",
       "1      251.922600  8.309002  313.035133  0.000000    1.0   1.0   1.0   1.0   \n",
       "2      251.922600  8.309986  313.201733  0.000000    1.0   1.0   1.0   1.0   \n",
       "3      251.922600  8.309515  313.391437  0.000000    1.0   1.0   1.0   1.0   \n",
       "4      251.922600  8.310445  313.572593  0.000000    1.0   1.0   1.0   1.0   \n",
       "...           ...       ...         ...       ...    ...   ...   ...   ...   \n",
       "16495  262.117613  8.392004  328.743903  2.441782    2.0   1.0   1.0   2.0   \n",
       "16496  261.994780  8.395080  328.728520  2.442059    2.0   1.0   1.0   2.0   \n",
       "16497  261.984100  8.392432  328.685000  2.442764    2.0   1.0   1.0   2.0   \n",
       "16498  262.005433  8.390680  328.567070  2.442059    2.0   1.0   1.0   2.0   \n",
       "16499  262.016100  8.391715  328.620853  2.442260    2.0   1.0   1.0   2.0   \n",
       "\n",
       "       P204  P205  P206    DPIT301    FIT301      LIT301  MV301  MV302  MV303  \\\n",
       "0       1.0   1.0   1.0   2.560983  0.000256  138.001473    1.0    1.0    1.0   \n",
       "1       1.0   1.0   1.0   2.560983  0.000256  137.997463    1.0    1.0    1.0   \n",
       "2       1.0   1.0   1.0   2.560983  0.000256  137.650337    1.0    1.0    1.0   \n",
       "3       1.0   1.0   1.0   2.562371  0.000256  137.475430    1.0    1.0    1.0   \n",
       "4       1.0   1.0   1.0   2.564185  0.000256  136.323223    1.0    1.0    1.0   \n",
       "...     ...   ...   ...        ...       ...         ...    ...    ...    ...   \n",
       "16495   1.0   2.0   1.0  19.697378  2.210396  948.864637    1.0    2.0    1.0   \n",
       "16496   1.0   2.0   1.0  19.694819  2.210802  950.720453    1.0    2.0    1.0   \n",
       "16497   1.0   2.0   1.0  19.651174  2.209111  952.979500    1.0    2.0    1.0   \n",
       "16498   1.0   2.0   1.0  19.687561  2.210276  953.821950    1.0    2.0    1.0   \n",
       "16499   1.0   2.0   1.0  19.728429  2.209965  955.096997    1.0    2.0    1.0   \n",
       "\n",
       "       MV304  P301  P302   AIT401      AIT402    FIT401      LIT401  P401  \\\n",
       "0        1.0   1.0   1.0    0.000  169.238700  0.000000  133.551660   1.0   \n",
       "1        1.0   1.0   1.0    0.000  169.336927  0.000000  132.621120   1.0   \n",
       "2        1.0   1.0   1.0    0.000  169.533480  0.000000  133.238917   1.0   \n",
       "3        1.0   1.0   1.0    0.000  169.596697  0.000000  132.054613   1.0   \n",
       "4        1.0   1.0   1.0    0.000  169.597557  0.000000  132.162273   1.0   \n",
       "...      ...   ...   ...      ...         ...       ...         ...   ...   \n",
       "16495    1.0   1.0   2.0  148.808  155.853213  1.716268  932.355810   1.0   \n",
       "16496    1.0   1.0   2.0  148.808  156.020690  1.717562  934.082277   1.0   \n",
       "16497    1.0   1.0   2.0  148.808  156.165107  1.717417  938.164577   1.0   \n",
       "16498    1.0   1.0   2.0  148.808  155.938637  1.718258  940.933093   1.0   \n",
       "16499    1.0   1.0   2.0  148.808  156.030080  1.717135  941.793140   1.0   \n",
       "\n",
       "       P402  P403  P404  UV401    AIT501      AIT502      AIT503      AIT504  \\\n",
       "0       1.0   1.0   1.0    1.0  7.445559  175.396040  260.702400  123.347827   \n",
       "1       1.0   1.0   1.0    1.0  7.444096  175.421673  260.702400  123.415783   \n",
       "2       1.0   1.0   1.0    1.0  7.444544  175.603710  260.702400  123.379893   \n",
       "3       1.0   1.0   1.0    1.0  7.444737  175.660953  260.702400  123.314500   \n",
       "4       1.0   1.0   1.0    1.0  7.443733  175.698533  260.747270  123.338877   \n",
       "...     ...   ...   ...    ...       ...         ...         ...         ...   \n",
       "16495   2.0   1.0   1.0    2.0  7.876250  144.885900  264.842373   12.266090   \n",
       "16496   2.0   1.0   1.0    2.0  7.877019  144.926100  264.855180   12.180211   \n",
       "16497   2.0   1.0   1.0    2.0  7.876314  144.916727  264.778260   12.090490   \n",
       "16498   2.0   1.0   1.0    2.0  7.876058  145.100373  264.630830   12.105872   \n",
       "16499   2.0   1.0   1.0    2.0  7.877820  145.167013  264.547500   12.149452   \n",
       "\n",
       "         FIT501    FIT502    FIT503    FIT504  P501  P502      PIT501  \\\n",
       "0      0.001538  0.001409  0.001664  0.000000   1.0   1.0    9.100231   \n",
       "1      0.001538  0.001409  0.001664  0.000000   1.0   1.0    9.058041   \n",
       "2      0.001538  0.001409  0.001664  0.000000   1.0   1.0    9.068188   \n",
       "3      0.001538  0.001409  0.001664  0.000000   1.0   1.0    9.068188   \n",
       "4      0.001538  0.001409  0.001664  0.000034   1.0   1.0    9.068188   \n",
       "...         ...       ...       ...       ...   ...   ...         ...   \n",
       "16495  1.726062  1.282836  0.735563  0.307807   2.0   1.0  251.054733   \n",
       "16496  1.728326  1.287610  0.735397  0.306763   2.0   1.0  251.252893   \n",
       "16497  1.728143  1.287204  0.735781  0.307876   2.0   1.0  251.173293   \n",
       "16498  1.728356  1.281841  0.735269  0.307171   2.0   1.0  251.176520   \n",
       "16499  1.726335  1.283814  0.735512  0.307436   2.0   1.0  251.078753   \n",
       "\n",
       "         PIT502      PIT503    FIT601  P601  P602  P603  Normal/Attack  \n",
       "0      0.000000    3.348500  0.000256   1.0   1.0   1.0            0.0  \n",
       "1      0.000000    3.348500  0.000256   1.0   1.0   1.0            0.0  \n",
       "2      0.000000    3.348500  0.000256   1.0   1.0   1.0            0.0  \n",
       "3      0.000000    3.348500  0.000256   1.0   1.0   1.0            0.0  \n",
       "4      0.000000    3.313787  0.000256   1.0   1.0   1.0            0.0  \n",
       "...         ...         ...       ...   ...   ...   ...            ...  \n",
       "16495  1.674516  189.845550  0.000128   1.0   1.0   1.0            0.0  \n",
       "16496  1.667574  189.996673  0.000128   1.0   1.0   1.0            0.0  \n",
       "16497  1.681991  189.921897  0.000128   1.0   1.0   1.0            0.0  \n",
       "16498  1.704418  189.868497  0.000128   1.0   1.0   1.0            0.0  \n",
       "16499  1.687865  189.840737  0.000128   1.0   1.0   1.0            0.0  \n",
       "\n",
       "[16500 rows x 53 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('/mnt/stud/home/vpulagura/experiment/OpenDatasets/SWaT/data/DownsampledNormal.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16500, 52), (14999, 52))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_down = pd.read_csv('/DownsampledNormal.csv')\n",
    "df_down['Timestamp'] = pd.to_datetime(df_down['Timestamp'])\n",
    "df_down = df_down.set_index(df_down['Timestamp'])\n",
    "df_down = df_down.drop(columns=['Timestamp'])\n",
    "df_train = df_down.drop(columns=['Normal/Attack'])\n",
    "\n",
    "df_down2 = pd.read_csv('/DownsampledAttack.csv')\n",
    "df_down2['Timestamp'] = pd.to_datetime(df_down2['Timestamp'])\n",
    "df_down2 = df_down2.set_index(df_down2['Timestamp'])\n",
    "df_down2 = df_down2.drop(columns=['Timestamp'])\n",
    "df_down.shape, df_down2.shape,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest = df_down2['Normal/Attack']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    13144\n",
       "1     1855\n",
       "Name: Normal/Attack, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.05780495471040375, 0.05889075843677577)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "54621/(495000+449919), 1855/(16500+14999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_down = pd.read_csv('/DownsampledNormal.csv')\n",
    "df_down = df_down.set_index(df_down['Timestamp'])\n",
    "df_down = df_down.drop(columns=['Timestamp'])\n",
    "df_train = df_down.drop(columns=['Normal/Attack'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2879, 51)\n",
      "{'model__batch_size': 256, 'model__encoding_dim': 30, 'model__epochs': 200, 'model__layer1': 50, 'model__layer2': 30}\n",
      "['1 days, F1: 0.25064414543372465, Acc: 0.30195346356423763, Prec: 0.14450771643145993, Rec: 0.9439353099730459']\n",
      "(5759, 51)\n",
      "{'model__batch_size': 128, 'model__encoding_dim': 20, 'model__epochs': 200, 'model__layer1': 30, 'model__layer2': 40}\n",
      "['1 days, F1: 0.25064414543372465, Acc: 0.30195346356423763, Prec: 0.14450771643145993, Rec: 0.9439353099730459', '2 days, F1: 0.2579150579150579, Acc: 0.359290619374625, Prec: 0.1505182514646237, Rec: 0.9002695417789758']\n",
      "(11519, 51)\n",
      "{'model__batch_size': 128, 'model__encoding_dim': 30, 'model__epochs': 200, 'model__layer1': 50, 'model__layer2': 30}\n",
      "['1 days, F1: 0.25064414543372465, Acc: 0.30195346356423763, Prec: 0.14450771643145993, Rec: 0.9439353099730459', '2 days, F1: 0.2579150579150579, Acc: 0.359290619374625, Prec: 0.1505182514646237, Rec: 0.9002695417789758', '4 days, F1: 0.2573099415204678, Acc: 0.3480232015467698, Prec: 0.14975247524752475, Rec: 0.9132075471698113']\n",
      "(16499, 51)\n",
      "{'model__batch_size': 128, 'model__encoding_dim': 5, 'model__epochs': 200, 'model__layer1': 50, 'model__layer2': 20}\n",
      "['1 days, F1: 0.25064414543372465, Acc: 0.30195346356423763, Prec: 0.14450771643145993, Rec: 0.9439353099730459', '2 days, F1: 0.2579150579150579, Acc: 0.359290619374625, Prec: 0.1505182514646237, Rec: 0.9002695417789758', '4 days, F1: 0.2573099415204678, Acc: 0.3480232015467698, Prec: 0.14975247524752475, Rec: 0.9132075471698113', '7 days, F1: 0.2873084757771676, Acc: 0.46349756650443363, Prec: 0.17189487070792708, Rec: 0.8743935309973045']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold, KFold\n",
    "from sklearn import linear_model, metrics, preprocessing\n",
    "from math import sqrt, floor\n",
    "from datetime import datetime, timedelta\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, BatchNormalization, Input, LSTM,Dense,RepeatVector, TimeDistributed , LeakyReLU\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, IsolationForest\n",
    "from sklearn.metrics import r2_score, make_scorer, accuracy_score, mean_squared_error, mean_absolute_error\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl\n",
    "import tensorflow as tf\n",
    "LeakyReLU = LeakyReLU(alpha=0.1)\n",
    "import warnings\n",
    "import pandas as pd\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "import time\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "import math\n",
    "from sklearn.decomposition import PCA\n",
    "from numpy import array\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import keras\n",
    "from keras.layers import Dense, Dropout, Activation, BatchNormalization, Input,Conv2D, Conv1D, Conv1DTranspose,MaxPooling1D,AveragePooling1D,  UpSampling1D\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras import optimizers, Sequential\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from statistics import mean\n",
    "from tcn import TCN\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score,recall_score\n",
    "\n",
    "train_path = '/train/'\n",
    "test_path = '/test/'\n",
    "\n",
    "def encoder(input_dim, encoding_dim, layer1, layer2):\n",
    "    x = Dense(layer1, activation = 'relu')(input_dim)\n",
    "    x = Dense(layer2, activation = 'relu')(x)\n",
    "    x = Dense(encoding_dim, activation = 'relu')(x)\n",
    "    return x\n",
    "\n",
    "def decoder(encoding_dim, decod_dim, layer1, layer2):\n",
    "    x = Dense(layer2, activation = 'relu')(encoding_dim)\n",
    "    x = Dense(layer1, activation = 'relu')(x)\n",
    "    x = Dense(decod_dim, activation = 'relu')(x)\n",
    "    return x\n",
    "\n",
    "def create_autoencoder_model2(encoding_dim = 4, input_dim = 51, decod_dim=51,layer1=40, layer2=30):\n",
    "    input_dim = Input(shape = (input_dim, ))\n",
    "    encoder_out = encoder(input_dim, encoding_dim, layer1, layer2)\n",
    "    decoder_out = decoder(encoder_out, decod_dim, layer1, layer2)\n",
    "    autoencoder = Model(inputs = input_dim, outputs = decoder_out)\n",
    "    autoencoder.compile(optimizer = 'adam', loss = 'mse')\n",
    "    return autoencoder\n",
    "\n",
    "import ast\n",
    "df_hyp = pd.read_csv('./AE_HYP.csv')\n",
    "def getHyperParams(file):\n",
    "    param_dict = ast.literal_eval(df_hyp.loc[df_hyp['file'] == file]['Hyperparameters'].values[0])\n",
    "    print(param_dict)\n",
    "    return param_dict['model__batch_size'], param_dict['model__encoding_dim'], param_dict['model__epochs'],param_dict['model__layer1'], param_dict['model__layer2'] \n",
    "\n",
    "callback1 = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10, verbose=1)\n",
    "\n",
    "df_down = pd.read_csv('/DownsampledNormal.csv')\n",
    "df_down['Timestamp'] = pd.to_datetime(df_down['Timestamp'])\n",
    "df_down = df_down.set_index(df_down['Timestamp'])\n",
    "df_down = df_down.drop(columns=['Timestamp'])\n",
    "ytrain_df = df_down[['Normal/Attack']]\n",
    "df_train = df_down.drop(columns=['Normal/Attack'])\n",
    "\n",
    "df_down2 = pd.read_csv('/DownsampledAttack.csv')\n",
    "df_down2['Timestamp'] = pd.to_datetime(df_down2['Timestamp'])\n",
    "df_down2 = df_down2.set_index(df_down2['Timestamp'])\n",
    "df_down2 = df_down2.drop(columns=['Timestamp'])\n",
    "ytest = df_down2['Normal/Attack']\n",
    "df_test = df_down2.drop(columns=['Normal/Attack'])\n",
    "format = '%Y-%m-%d %H:%M:%S'\n",
    "end_date = datetime.strptime(str(df_train.tail(1).index[0]), format)\n",
    "lst=[]\n",
    "source_dict_results = {}\n",
    "source_dict_results_train = {}\n",
    "for i in [1,2,4,7]:\n",
    "    start_date = end_date-timedelta(days=i)\n",
    "    ytrain = ytrain_df[(ytrain_df.index > start_date) & (ytrain_df.index < end_date)]\n",
    "    x_train = df_train[(df_train.index > start_date) & (df_train.index < end_date)]\n",
    "    \n",
    "    scalar = MinMaxScaler()\n",
    "    scalar.fit(x_train)\n",
    "    xtrain = scalar.transform(x_train)\n",
    "    xtest = scalar.transform(df_test)\n",
    "    print(x_train.shape)\n",
    "    model__batch_size,model__encoding_dim, model__epochs, model__layer1, model__layer2 = getHyperParams(i)                                               \n",
    "    model  = create_autoencoder_model2(layer1=model__layer1, layer2=model__layer2, encoding_dim=model__encoding_dim)\n",
    "    model.fit(xtrain, xtrain, epochs=model__epochs, batch_size=model__batch_size, verbose=False,validation_split=0.1, callbacks=callback1)\n",
    "    test_enc = model.predict(xtest)\n",
    "    train_enc = model.predict(xtrain)\n",
    "    test_mses = np.mean(np.power(xtest- test_enc, 2), axis=1)\n",
    "    train_mses = np.mean(np.power(xtrain- train_enc, 2), axis=1)\n",
    "    test_maes = np.mean(xtest- test_enc, axis=1)\n",
    "    train_maes = np.mean(xtrain- train_enc, axis=1)\n",
    "    mse_threshold = np.max(train_mses)\n",
    "    mae_threshold = np.max(train_maes)\n",
    "    ypred_mse = np.where(test_mses>mse_threshold,1,0)\n",
    "    ypred_mae = np.where(test_maes>mae_threshold,1,0)\n",
    "    lst.append(str(i)+' days'+', F1: '+str(f1_score(y_true=ytest, y_pred=ypred_mse))+', Acc: '+str(accuracy_score(y_true=ytest, y_pred=ypred_mse))+', Prec: '+str(precision_score(y_true=ytest, y_pred=ypred_mse))+', Rec: '+str(recall_score(y_true=ytest, y_pred=ypred_mse)))\n",
    "    print(lst)\n",
    "    df = pd.DataFrame({'Model':['AE'],'days':[str(i)+'D'],'F1':[str(f1_score(y_true=ytest, y_pred=ypred_mse))], 'Acc':[str(accuracy_score(y_true=ytest, y_pred=ypred_mse))], 'Prec':[str(precision_score(y_true=ytest, y_pred=ypred_mse))], 'Rec':[str(recall_score(y_true=ytest, y_pred=ypred_mse))]})\n",
    "    df.to_csv('./SWaTResults/metrics.csv', mode = 'a', header=False)\n",
    "    test_df = pd.DataFrame(test_mses)\n",
    "    test_df['mse_scores'] = test_df[0]\n",
    "    test_df['ytrue'] = ytest\n",
    "    test_df['mae_scores'] = test_maes\n",
    "    test_df['ypred_mse'] = ypred_mse\n",
    "    test_df['ypred_mae'] = ypred_mae\n",
    "    test_df['Datetime'] = ytest.index\n",
    "    test_df = test_df[['Datetime','ytrue','ypred_mse','ypred_mae','mse_scores', 'mae_scores']]\n",
    "    source_dict_results[i] = test_df\n",
    "    \n",
    "    train_df = pd.DataFrame(train_mses)\n",
    "    train_df['mse_scores'] = train_df[0]\n",
    "    train_df['ytrue'] = ytrain.values\n",
    "    train_df['mae_scores'] = train_maes\n",
    "    train_df['Datetime'] = ytrain.index\n",
    "    train_df = train_df[['Datetime','ytrue','mse_scores', 'mae_scores']]\n",
    "    source_dict_results_train[i] = train_df\n",
    "import pickle\n",
    "with open(test_path+'test_STL_AE.pkl', 'wb') as f:\n",
    "    pickle.dump(source_dict_results, f) \n",
    "with open(train_path+'train_STL_AE.pkl', 'wb') as f:\n",
    "    pickle.dump(source_dict_results_train, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1 days, F1: 0.25689027561102445, Acc: 0.3330888725915061, Prec: 0.14897466827503017, Rec: 0.9320754716981132',\n",
       " '2 days, F1: 0.2565041580834669, Acc: 0.3502900193346223, Prec: 0.14939566299324564, Rec: 0.9061994609164421',\n",
       " '4 days, F1: 0.262972060178078, Acc: 0.3598239882658844, Prec: 0.1533160297144903, Rec: 0.9234501347708894',\n",
       " '7 days, F1: 0.2749000595389981, Acc: 0.43162877525168347, Prec: 0.16319935366592608, Rec: 0.8711590296495957']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2 days, F1: 0.2562733582487987, Acc: 0.34988999266617776, Prec: 0.14925373134328357, Rec: 0.9056603773584906',\n",
       " '4 days, F1: 0.2590819929384072, Acc: 0.3704246949796653, Prec: 0.15160697887970614, Rec: 0.8900269541778976',\n",
       " '7 days, F1: 0.2745560138035519, Acc: 0.4253616907793853, Prec: 0.16267703969678834, Rec: 0.879245283018868']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>ytrue</th>\n",
       "      <th>mse_scores</th>\n",
       "      <th>mae_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-12-22 16:30:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009331</td>\n",
       "      <td>0.012296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-12-22 16:30:30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009343</td>\n",
       "      <td>0.012220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-12-22 16:31:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009328</td>\n",
       "      <td>0.012368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-12-22 16:31:30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009318</td>\n",
       "      <td>0.012379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-12-22 16:32:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009316</td>\n",
       "      <td>0.012364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16494</th>\n",
       "      <td>2015-12-28 09:57:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001792</td>\n",
       "      <td>0.008101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16495</th>\n",
       "      <td>2015-12-28 09:57:30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002014</td>\n",
       "      <td>0.008253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16496</th>\n",
       "      <td>2015-12-28 09:58:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>0.008307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16497</th>\n",
       "      <td>2015-12-28 09:58:30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>0.008630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16498</th>\n",
       "      <td>2015-12-28 09:59:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002119</td>\n",
       "      <td>0.008681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16499 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Datetime  ytrue  mse_scores  mae_scores\n",
       "0     2015-12-22 16:30:00    0.0    0.009331    0.012296\n",
       "1     2015-12-22 16:30:30    0.0    0.009343    0.012220\n",
       "2     2015-12-22 16:31:00    0.0    0.009328    0.012368\n",
       "3     2015-12-22 16:31:30    0.0    0.009318    0.012379\n",
       "4     2015-12-22 16:32:00    0.0    0.009316    0.012364\n",
       "...                   ...    ...         ...         ...\n",
       "16494 2015-12-28 09:57:00    0.0    0.001792    0.008101\n",
       "16495 2015-12-28 09:57:30    0.0    0.002014    0.008253\n",
       "16496 2015-12-28 09:58:00    0.0    0.002012    0.008307\n",
       "16497 2015-12-28 09:58:30    0.0    0.002041    0.008630\n",
       "16498 2015-12-28 09:59:00    0.0    0.002119    0.008681\n",
       "\n",
       "[16499 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-22 13:01:31.479353: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-06-22 13:01:31.479448: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 144 candidates, totalling 288 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-22 13:02:56.603697: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-06-22 13:02:56.604334: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-06-22 13:02:56.604760: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-06-22 13:02:56.605303: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2023-06-22 13:02:56.605953: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2023-06-22 13:02:56.606603: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-06-22 13:02:56.607021: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-06-22 13:02:56.607454: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-06-22 13:02:56.607481: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-06-22 13:02:56.611978: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model__batch_size=256, model__encoding_dim=30, model__epochs=100, model__layer1=50, model__layer2=40; total time=   9.5s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=30, model__epochs=100, model__layer1=50, model__layer2=40; total time=   3.6s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=30, model__epochs=100, model__layer1=50, model__layer2=30; total time=   2.7s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=30, model__epochs=100, model__layer1=50, model__layer2=30; total time=   2.8s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=30, model__epochs=100, model__layer1=50, model__layer2=20; total time=   3.0s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=30, model__epochs=100, model__layer1=50, model__layer2=20; total time=   3.0s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=30, model__epochs=100, model__layer1=40, model__layer2=40; total time=   2.8s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=30, model__epochs=100, model__layer1=40, model__layer2=40; total time=   3.5s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=30, model__epochs=100, model__layer1=40, model__layer2=30; total time=   3.0s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=30, model__epochs=100, model__layer1=40, model__layer2=30; total time=   3.6s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=30, model__epochs=100, model__layer1=40, model__layer2=20; total time=   3.6s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=30, model__epochs=100, model__layer1=40, model__layer2=20; total time=   3.7s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=30, model__epochs=100, model__layer1=30, model__layer2=40; total time=   3.5s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=30, model__epochs=100, model__layer1=30, model__layer2=40; total time=   3.6s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=30, model__epochs=100, model__layer1=30, model__layer2=30; total time=   3.0s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=30, model__epochs=100, model__layer1=30, model__layer2=30; total time=   4.1s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=30, model__epochs=100, model__layer1=30, model__layer2=20; total time=   2.6s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=30, model__epochs=100, model__layer1=30, model__layer2=20; total time=   2.9s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=30, model__epochs=200, model__layer1=50, model__layer2=40; total time=   5.2s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=30, model__epochs=200, model__layer1=50, model__layer2=40; total time=   6.1s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=30, model__epochs=200, model__layer1=50, model__layer2=30; total time=   5.9s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=30, model__epochs=200, model__layer1=50, model__layer2=30; total time=   4.8s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=30, model__epochs=200, model__layer1=50, model__layer2=20; total time=   6.2s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=30, model__epochs=200, model__layer1=50, model__layer2=20; total time=   4.8s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=30, model__epochs=200, model__layer1=40, model__layer2=40; total time=   4.7s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=30, model__epochs=200, model__layer1=40, model__layer2=40; total time=   5.0s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=30, model__epochs=200, model__layer1=40, model__layer2=30; total time=   5.7s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=30, model__epochs=200, model__layer1=40, model__layer2=30; total time=   3.3s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=30, model__epochs=200, model__layer1=40, model__layer2=20; total time=   3.4s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=30, model__epochs=200, model__layer1=40, model__layer2=20; total time=   5.9s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=30, model__epochs=200, model__layer1=30, model__layer2=40; total time=   3.7s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=30, model__epochs=200, model__layer1=30, model__layer2=40; total time=   3.7s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=30, model__epochs=200, model__layer1=30, model__layer2=30; total time=   6.1s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=30, model__epochs=200, model__layer1=30, model__layer2=30; total time=   6.2s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=30, model__epochs=200, model__layer1=30, model__layer2=20; total time=   6.1s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=30, model__epochs=200, model__layer1=30, model__layer2=20; total time=   6.5s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=20, model__epochs=100, model__layer1=50, model__layer2=40; total time=   3.1s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=20, model__epochs=100, model__layer1=50, model__layer2=40; total time=   2.9s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=20, model__epochs=100, model__layer1=50, model__layer2=30; total time=   3.5s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=20, model__epochs=100, model__layer1=50, model__layer2=30; total time=   3.3s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=20, model__epochs=100, model__layer1=50, model__layer2=20; total time=   3.5s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=20, model__epochs=100, model__layer1=50, model__layer2=20; total time=   2.7s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=20, model__epochs=100, model__layer1=40, model__layer2=40; total time=   3.4s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=20, model__epochs=100, model__layer1=40, model__layer2=40; total time=   3.5s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=20, model__epochs=100, model__layer1=40, model__layer2=30; total time=   2.8s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=20, model__epochs=100, model__layer1=40, model__layer2=30; total time=   3.4s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=20, model__epochs=100, model__layer1=40, model__layer2=20; total time=   3.7s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=20, model__epochs=100, model__layer1=40, model__layer2=20; total time=   3.5s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=20, model__epochs=100, model__layer1=30, model__layer2=40; total time=   2.7s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=20, model__epochs=100, model__layer1=30, model__layer2=40; total time=   2.2s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=20, model__epochs=100, model__layer1=30, model__layer2=30; total time=   3.6s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=20, model__epochs=100, model__layer1=30, model__layer2=30; total time=   3.5s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=20, model__epochs=100, model__layer1=30, model__layer2=20; total time=   2.4s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=20, model__epochs=100, model__layer1=30, model__layer2=20; total time=   2.2s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=20, model__epochs=200, model__layer1=50, model__layer2=40; total time=   6.1s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=20, model__epochs=200, model__layer1=50, model__layer2=40; total time=   6.5s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=20, model__epochs=200, model__layer1=50, model__layer2=30; total time=   4.9s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=20, model__epochs=200, model__layer1=50, model__layer2=30; total time=   6.1s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=20, model__epochs=200, model__layer1=50, model__layer2=20; total time=   3.6s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=20, model__epochs=200, model__layer1=50, model__layer2=20; total time=   3.5s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=20, model__epochs=200, model__layer1=40, model__layer2=40; total time=   5.8s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=20, model__epochs=200, model__layer1=40, model__layer2=40; total time=   3.7s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=20, model__epochs=200, model__layer1=40, model__layer2=30; total time=   5.8s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=20, model__epochs=200, model__layer1=40, model__layer2=30; total time=   3.2s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=20, model__epochs=200, model__layer1=40, model__layer2=20; total time=   3.8s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=20, model__epochs=200, model__layer1=40, model__layer2=20; total time=   5.9s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=20, model__epochs=200, model__layer1=30, model__layer2=40; total time=   3.6s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=20, model__epochs=200, model__layer1=30, model__layer2=40; total time=   6.0s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=20, model__epochs=200, model__layer1=30, model__layer2=30; total time=   6.0s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=20, model__epochs=200, model__layer1=30, model__layer2=30; total time=   4.3s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=20, model__epochs=200, model__layer1=30, model__layer2=20; total time=   3.8s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=20, model__epochs=200, model__layer1=30, model__layer2=20; total time=   4.3s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=10, model__epochs=100, model__layer1=50, model__layer2=40; total time=   2.8s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=10, model__epochs=100, model__layer1=50, model__layer2=40; total time=   3.5s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=10, model__epochs=100, model__layer1=50, model__layer2=30; total time=   3.5s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=10, model__epochs=100, model__layer1=50, model__layer2=30; total time=   4.0s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=10, model__epochs=100, model__layer1=50, model__layer2=20; total time=   3.4s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=10, model__epochs=100, model__layer1=50, model__layer2=20; total time=   3.6s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=10, model__epochs=100, model__layer1=40, model__layer2=40; total time=   3.5s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=10, model__epochs=100, model__layer1=40, model__layer2=40; total time=   2.6s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=10, model__epochs=100, model__layer1=40, model__layer2=30; total time=   3.2s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=10, model__epochs=100, model__layer1=40, model__layer2=30; total time=   3.5s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=10, model__epochs=100, model__layer1=40, model__layer2=20; total time=   3.5s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=10, model__epochs=100, model__layer1=40, model__layer2=20; total time=   3.5s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=10, model__epochs=100, model__layer1=30, model__layer2=40; total time=   3.9s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=10, model__epochs=100, model__layer1=30, model__layer2=40; total time=   2.7s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=10, model__epochs=100, model__layer1=30, model__layer2=30; total time=   3.5s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=10, model__epochs=100, model__layer1=30, model__layer2=30; total time=   3.4s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=10, model__epochs=100, model__layer1=30, model__layer2=20; total time=   3.5s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=10, model__epochs=100, model__layer1=30, model__layer2=20; total time=   2.6s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=10, model__epochs=200, model__layer1=50, model__layer2=40; total time=   6.0s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=10, model__epochs=200, model__layer1=50, model__layer2=40; total time=   6.1s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=10, model__epochs=200, model__layer1=50, model__layer2=30; total time=   5.9s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=10, model__epochs=200, model__layer1=50, model__layer2=30; total time=   6.1s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=10, model__epochs=200, model__layer1=50, model__layer2=20; total time=   4.9s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=10, model__epochs=200, model__layer1=50, model__layer2=20; total time=   6.1s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=10, model__epochs=200, model__layer1=40, model__layer2=40; total time=   4.1s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=10, model__epochs=200, model__layer1=40, model__layer2=40; total time=   4.4s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=10, model__epochs=200, model__layer1=40, model__layer2=30; total time=   4.5s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=10, model__epochs=200, model__layer1=40, model__layer2=30; total time=   5.8s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=10, model__epochs=200, model__layer1=40, model__layer2=20; total time=   6.1s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=10, model__epochs=200, model__layer1=40, model__layer2=20; total time=   5.8s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=10, model__epochs=200, model__layer1=30, model__layer2=40; total time=   4.4s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=10, model__epochs=200, model__layer1=30, model__layer2=40; total time=   6.1s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=10, model__epochs=200, model__layer1=30, model__layer2=30; total time=   6.1s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=10, model__epochs=200, model__layer1=30, model__layer2=30; total time=   4.3s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=10, model__epochs=200, model__layer1=30, model__layer2=20; total time=   4.1s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=10, model__epochs=200, model__layer1=30, model__layer2=20; total time=   4.1s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=5, model__epochs=100, model__layer1=50, model__layer2=40; total time=   2.3s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=5, model__epochs=100, model__layer1=50, model__layer2=40; total time=   2.7s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=5, model__epochs=100, model__layer1=50, model__layer2=30; total time=   3.5s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=5, model__epochs=100, model__layer1=50, model__layer2=30; total time=   2.8s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=5, model__epochs=100, model__layer1=50, model__layer2=20; total time=   2.1s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=5, model__epochs=100, model__layer1=50, model__layer2=20; total time=   3.4s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=5, model__epochs=100, model__layer1=40, model__layer2=40; total time=   3.1s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=5, model__epochs=100, model__layer1=40, model__layer2=40; total time=   3.5s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=5, model__epochs=100, model__layer1=40, model__layer2=30; total time=   3.2s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=5, model__epochs=100, model__layer1=40, model__layer2=30; total time=   2.7s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=5, model__epochs=100, model__layer1=40, model__layer2=20; total time=   3.5s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=5, model__epochs=100, model__layer1=40, model__layer2=20; total time=   2.6s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=5, model__epochs=100, model__layer1=30, model__layer2=40; total time=   2.2s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=5, model__epochs=100, model__layer1=30, model__layer2=40; total time=   3.4s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=5, model__epochs=100, model__layer1=30, model__layer2=30; total time=   2.6s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=5, model__epochs=100, model__layer1=30, model__layer2=30; total time=   3.5s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=5, model__epochs=100, model__layer1=30, model__layer2=20; total time=   3.8s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=5, model__epochs=100, model__layer1=30, model__layer2=20; total time=   3.5s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=5, model__epochs=200, model__layer1=50, model__layer2=40; total time=   6.1s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=5, model__epochs=200, model__layer1=50, model__layer2=40; total time=   6.1s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=5, model__epochs=200, model__layer1=50, model__layer2=30; total time=   4.2s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=5, model__epochs=200, model__layer1=50, model__layer2=30; total time=   6.1s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=5, model__epochs=200, model__layer1=50, model__layer2=20; total time=   4.3s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=5, model__epochs=200, model__layer1=50, model__layer2=20; total time=   5.8s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=5, model__epochs=200, model__layer1=40, model__layer2=40; total time=   4.5s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=5, model__epochs=200, model__layer1=40, model__layer2=40; total time=   6.1s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=5, model__epochs=200, model__layer1=40, model__layer2=30; total time=   4.9s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=5, model__epochs=200, model__layer1=40, model__layer2=30; total time=   6.0s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=5, model__epochs=200, model__layer1=40, model__layer2=20; total time=   4.3s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=5, model__epochs=200, model__layer1=40, model__layer2=20; total time=   4.0s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=5, model__epochs=200, model__layer1=30, model__layer2=40; total time=   5.8s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=5, model__epochs=200, model__layer1=30, model__layer2=40; total time=   6.0s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=5, model__epochs=200, model__layer1=30, model__layer2=30; total time=   4.2s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=5, model__epochs=200, model__layer1=30, model__layer2=30; total time=   4.3s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=5, model__epochs=200, model__layer1=30, model__layer2=20; total time=   6.1s\n",
      "[CV] END model__batch_size=256, model__encoding_dim=5, model__epochs=200, model__layer1=30, model__layer2=20; total time=   6.1s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=30, model__epochs=100, model__layer1=50, model__layer2=40; total time=   6.1s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=30, model__epochs=100, model__layer1=50, model__layer2=40; total time=   4.8s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=30, model__epochs=100, model__layer1=50, model__layer2=30; total time=   4.2s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=30, model__epochs=100, model__layer1=50, model__layer2=30; total time=   4.3s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=30, model__epochs=100, model__layer1=50, model__layer2=20; total time=   3.9s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=30, model__epochs=100, model__layer1=50, model__layer2=20; total time=   3.9s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=30, model__epochs=100, model__layer1=40, model__layer2=40; total time=   6.1s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=30, model__epochs=100, model__layer1=40, model__layer2=40; total time=   6.2s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=30, model__epochs=100, model__layer1=40, model__layer2=30; total time=   6.1s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=30, model__epochs=100, model__layer1=40, model__layer2=30; total time=   6.1s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=30, model__epochs=100, model__layer1=40, model__layer2=20; total time=   6.5s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=30, model__epochs=100, model__layer1=40, model__layer2=20; total time=   6.1s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=30, model__epochs=100, model__layer1=30, model__layer2=40; total time=   6.1s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=30, model__epochs=100, model__layer1=30, model__layer2=40; total time=   6.1s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=30, model__epochs=100, model__layer1=30, model__layer2=30; total time=   4.2s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=30, model__epochs=100, model__layer1=30, model__layer2=30; total time=   6.2s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=30, model__epochs=100, model__layer1=30, model__layer2=20; total time=   4.0s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=30, model__epochs=100, model__layer1=30, model__layer2=20; total time=   4.0s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=30, model__epochs=200, model__layer1=50, model__layer2=40; total time=   7.8s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=30, model__epochs=200, model__layer1=50, model__layer2=40; total time=  11.3s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=30, model__epochs=200, model__layer1=50, model__layer2=30; total time=   8.1s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=30, model__epochs=200, model__layer1=50, model__layer2=30; total time=   7.6s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=30, model__epochs=200, model__layer1=50, model__layer2=20; total time=  11.2s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=30, model__epochs=200, model__layer1=50, model__layer2=20; total time=  11.2s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=30, model__epochs=200, model__layer1=40, model__layer2=40; total time=  11.3s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=30, model__epochs=200, model__layer1=40, model__layer2=40; total time=   7.7s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=30, model__epochs=200, model__layer1=40, model__layer2=30; total time=   7.5s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=30, model__epochs=200, model__layer1=40, model__layer2=30; total time=  11.2s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=30, model__epochs=200, model__layer1=40, model__layer2=20; total time=   6.7s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=30, model__epochs=200, model__layer1=40, model__layer2=20; total time=   7.4s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=30, model__epochs=200, model__layer1=30, model__layer2=40; total time=   8.0s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=30, model__epochs=200, model__layer1=30, model__layer2=40; total time=   7.5s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=30, model__epochs=200, model__layer1=30, model__layer2=30; total time=   7.5s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=30, model__epochs=200, model__layer1=30, model__layer2=30; total time=  11.3s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=30, model__epochs=200, model__layer1=30, model__layer2=20; total time=  11.3s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=30, model__epochs=200, model__layer1=30, model__layer2=20; total time=   7.1s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=20, model__epochs=100, model__layer1=50, model__layer2=40; total time=   3.8s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=20, model__epochs=100, model__layer1=50, model__layer2=40; total time=   3.1s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=20, model__epochs=100, model__layer1=50, model__layer2=30; total time=   3.5s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=20, model__epochs=100, model__layer1=50, model__layer2=30; total time=   3.4s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=20, model__epochs=100, model__layer1=50, model__layer2=20; total time=   3.3s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=20, model__epochs=100, model__layer1=50, model__layer2=20; total time=   3.6s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=20, model__epochs=100, model__layer1=40, model__layer2=40; total time=   3.2s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=20, model__epochs=100, model__layer1=40, model__layer2=40; total time=   3.5s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=20, model__epochs=100, model__layer1=40, model__layer2=30; total time=   3.3s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=20, model__epochs=100, model__layer1=40, model__layer2=30; total time=   3.3s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=20, model__epochs=100, model__layer1=40, model__layer2=20; total time=   2.9s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=20, model__epochs=100, model__layer1=40, model__layer2=20; total time=   3.1s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=20, model__epochs=100, model__layer1=30, model__layer2=40; total time=   3.3s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=20, model__epochs=100, model__layer1=30, model__layer2=40; total time=   3.3s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=20, model__epochs=100, model__layer1=30, model__layer2=30; total time=   3.9s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=20, model__epochs=100, model__layer1=30, model__layer2=30; total time=   3.5s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=20, model__epochs=100, model__layer1=30, model__layer2=20; total time=   3.5s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=20, model__epochs=100, model__layer1=30, model__layer2=20; total time=   3.2s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=20, model__epochs=200, model__layer1=50, model__layer2=40; total time=   5.8s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=20, model__epochs=200, model__layer1=50, model__layer2=40; total time=   5.5s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=20, model__epochs=200, model__layer1=50, model__layer2=30; total time=   5.8s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=20, model__epochs=200, model__layer1=50, model__layer2=30; total time=   6.1s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=20, model__epochs=200, model__layer1=50, model__layer2=20; total time=   5.2s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=20, model__epochs=200, model__layer1=50, model__layer2=20; total time=   5.6s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=20, model__epochs=200, model__layer1=40, model__layer2=40; total time=   6.0s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=20, model__epochs=200, model__layer1=40, model__layer2=40; total time=   5.3s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=20, model__epochs=200, model__layer1=40, model__layer2=30; total time=   5.7s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=20, model__epochs=200, model__layer1=40, model__layer2=30; total time=   6.0s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=20, model__epochs=200, model__layer1=40, model__layer2=20; total time=   5.2s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=20, model__epochs=200, model__layer1=40, model__layer2=20; total time=   6.1s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=20, model__epochs=200, model__layer1=30, model__layer2=40; total time=   5.4s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=20, model__epochs=200, model__layer1=30, model__layer2=40; total time=   5.5s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=20, model__epochs=200, model__layer1=30, model__layer2=30; total time=   6.1s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=20, model__epochs=200, model__layer1=30, model__layer2=30; total time=   6.1s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=20, model__epochs=200, model__layer1=30, model__layer2=20; total time=   6.0s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=20, model__epochs=200, model__layer1=30, model__layer2=20; total time=   5.5s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=10, model__epochs=100, model__layer1=50, model__layer2=40; total time=   3.0s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=10, model__epochs=100, model__layer1=50, model__layer2=40; total time=   3.3s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=10, model__epochs=100, model__layer1=50, model__layer2=30; total time=   3.3s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=10, model__epochs=100, model__layer1=50, model__layer2=30; total time=   3.5s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=10, model__epochs=100, model__layer1=50, model__layer2=20; total time=   3.3s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=10, model__epochs=100, model__layer1=50, model__layer2=20; total time=   2.8s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=10, model__epochs=100, model__layer1=40, model__layer2=40; total time=   3.5s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=10, model__epochs=100, model__layer1=40, model__layer2=40; total time=   3.5s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=10, model__epochs=100, model__layer1=40, model__layer2=30; total time=   3.5s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=10, model__epochs=100, model__layer1=40, model__layer2=30; total time=   3.5s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=10, model__epochs=100, model__layer1=40, model__layer2=20; total time=   2.9s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=10, model__epochs=100, model__layer1=40, model__layer2=20; total time=   3.2s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=10, model__epochs=100, model__layer1=30, model__layer2=40; total time=   3.2s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=10, model__epochs=100, model__layer1=30, model__layer2=40; total time=   3.2s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=10, model__epochs=100, model__layer1=30, model__layer2=30; total time=   3.1s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=10, model__epochs=100, model__layer1=30, model__layer2=30; total time=   2.9s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=10, model__epochs=100, model__layer1=30, model__layer2=20; total time=   3.2s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=10, model__epochs=100, model__layer1=30, model__layer2=20; total time=   3.5s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=10, model__epochs=200, model__layer1=50, model__layer2=40; total time=   6.1s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=10, model__epochs=200, model__layer1=50, model__layer2=40; total time=   5.7s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=10, model__epochs=200, model__layer1=50, model__layer2=30; total time=   5.8s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=10, model__epochs=200, model__layer1=50, model__layer2=30; total time=   5.5s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=10, model__epochs=200, model__layer1=50, model__layer2=20; total time=   5.3s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=10, model__epochs=200, model__layer1=50, model__layer2=20; total time=   5.6s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=10, model__epochs=200, model__layer1=40, model__layer2=40; total time=   5.3s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=10, model__epochs=200, model__layer1=40, model__layer2=40; total time=   5.3s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=10, model__epochs=200, model__layer1=40, model__layer2=30; total time=   5.6s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=10, model__epochs=200, model__layer1=40, model__layer2=30; total time=   5.2s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=10, model__epochs=200, model__layer1=40, model__layer2=20; total time=   6.0s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=10, model__epochs=200, model__layer1=40, model__layer2=20; total time=   6.5s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=10, model__epochs=200, model__layer1=30, model__layer2=40; total time=   6.1s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=10, model__epochs=200, model__layer1=30, model__layer2=40; total time=   5.5s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=10, model__epochs=200, model__layer1=30, model__layer2=30; total time=   5.5s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=10, model__epochs=200, model__layer1=30, model__layer2=30; total time=   5.3s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=10, model__epochs=200, model__layer1=30, model__layer2=20; total time=   5.5s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=10, model__epochs=200, model__layer1=30, model__layer2=20; total time=   5.4s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=5, model__epochs=100, model__layer1=50, model__layer2=40; total time=   3.5s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=5, model__epochs=100, model__layer1=50, model__layer2=40; total time=   3.3s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=5, model__epochs=100, model__layer1=50, model__layer2=30; total time=   3.4s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=5, model__epochs=100, model__layer1=50, model__layer2=30; total time=   3.9s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=5, model__epochs=100, model__layer1=50, model__layer2=20; total time=   3.3s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=5, model__epochs=100, model__layer1=50, model__layer2=20; total time=   3.2s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=5, model__epochs=100, model__layer1=40, model__layer2=40; total time=   3.5s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=5, model__epochs=100, model__layer1=40, model__layer2=40; total time=   3.5s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=5, model__epochs=100, model__layer1=40, model__layer2=30; total time=   3.5s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=5, model__epochs=100, model__layer1=40, model__layer2=30; total time=   3.1s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=5, model__epochs=100, model__layer1=40, model__layer2=20; total time=   3.2s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=5, model__epochs=100, model__layer1=40, model__layer2=20; total time=   3.9s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=5, model__epochs=100, model__layer1=30, model__layer2=40; total time=   6.2s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=5, model__epochs=100, model__layer1=30, model__layer2=40; total time=   4.4s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=5, model__epochs=100, model__layer1=30, model__layer2=30; total time=   3.2s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=5, model__epochs=100, model__layer1=30, model__layer2=30; total time=   6.2s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=5, model__epochs=100, model__layer1=30, model__layer2=20; total time=   6.1s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=5, model__epochs=100, model__layer1=30, model__layer2=20; total time=   4.0s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=5, model__epochs=200, model__layer1=50, model__layer2=40; total time=   6.6s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=5, model__epochs=200, model__layer1=50, model__layer2=40; total time=  11.3s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=5, model__epochs=200, model__layer1=50, model__layer2=30; total time=   6.2s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=5, model__epochs=200, model__layer1=50, model__layer2=30; total time=   6.7s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=5, model__epochs=200, model__layer1=50, model__layer2=20; total time=   7.1s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=5, model__epochs=200, model__layer1=50, model__layer2=20; total time=  11.3s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=5, model__epochs=200, model__layer1=40, model__layer2=40; total time=   7.1s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=5, model__epochs=200, model__layer1=40, model__layer2=40; total time=   6.5s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=5, model__epochs=200, model__layer1=40, model__layer2=30; total time=  11.3s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=5, model__epochs=200, model__layer1=40, model__layer2=30; total time=   6.5s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=5, model__epochs=200, model__layer1=40, model__layer2=20; total time=  11.1s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=5, model__epochs=200, model__layer1=40, model__layer2=20; total time=  11.3s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=5, model__epochs=200, model__layer1=30, model__layer2=40; total time=  11.3s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=5, model__epochs=200, model__layer1=30, model__layer2=40; total time=   6.0s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=5, model__epochs=200, model__layer1=30, model__layer2=30; total time=  11.3s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=5, model__epochs=200, model__layer1=30, model__layer2=30; total time=   6.3s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=5, model__epochs=200, model__layer1=30, model__layer2=20; total time=   6.9s\n",
      "[CV] END model__batch_size=128, model__encoding_dim=5, model__epochs=200, model__layer1=30, model__layer2=20; total time=   6.5s\n",
      "   file model                                    Hyperparameters\n",
      "0     1    AE  {'model__batch_size': 256, 'model__encoding_di...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold, KFold\n",
    "from sklearn import linear_model, metrics, preprocessing\n",
    "from math import sqrt, floor\n",
    "from datetime import datetime, timedelta\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, BatchNormalization, Input, LSTM,Dense,RepeatVector, TimeDistributed , LeakyReLU\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, IsolationForest\n",
    "from sklearn.metrics import r2_score, make_scorer, accuracy_score, mean_squared_error, mean_absolute_error\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl\n",
    "import tensorflow as tf\n",
    "LeakyReLU = LeakyReLU(alpha=0.1)\n",
    "import warnings\n",
    "import pandas as pd\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "import time\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "import math\n",
    "from sklearn.decomposition import PCA\n",
    "from numpy import array\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import keras\n",
    "from keras.layers import Dense, Dropout, Activation, BatchNormalization, Input,Conv2D, Conv1D, Conv1DTranspose,MaxPooling1D,AveragePooling1D,  UpSampling1D\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras import optimizers, Sequential\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from statistics import mean\n",
    "from tcn import TCN\n",
    "\n",
    "\n",
    "def encoder(input_dim, encoding_dim, layer1, layer2):\n",
    "    x = Dense(layer1, activation = 'relu')(input_dim)\n",
    "    x = Dense(layer2, activation = 'relu')(x)\n",
    "    x = Dense(encoding_dim, activation = 'relu')(x)\n",
    "    return x\n",
    "\n",
    "def decoder(encoding_dim, decod_dim, layer1, layer2):\n",
    "    x = Dense(layer2, activation = 'relu')(encoding_dim)\n",
    "    x = Dense(layer1, activation = 'relu')(x)\n",
    "    x = Dense(decod_dim, activation = 'relu')(x)\n",
    "    return x\n",
    "\n",
    "def create_autoencoder_model2(encoding_dim = 4, input_dim = 51, decod_dim=51,layer1=40, layer2=30):\n",
    "    input_dim = Input(shape = (input_dim, ))\n",
    "    encoder_out = encoder(input_dim, encoding_dim, layer1, layer2)\n",
    "    decoder_out = decoder(encoder_out, decod_dim, layer1, layer2)\n",
    "    autoencoder = Model(inputs = input_dim, outputs = decoder_out)\n",
    "    autoencoder.compile(optimizer = 'adam', loss = 'mse')\n",
    "    return autoencoder\n",
    "\n",
    "callback1 = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10, verbose=1)\n",
    "\n",
    "df_down = pd.read_csv('/mnt/stud/home/vpulagura/experiment/OpenDatasets/SWaT/data/DownsampledNormal.csv')\n",
    "df_down['Timestamp'] = pd.to_datetime(df_down['Timestamp'])\n",
    "df_down = df_down.set_index(df_down['Timestamp'])\n",
    "df_down = df_down.drop(columns=['Timestamp'])\n",
    "df_train = df_down.drop(columns=['Normal/Attack'])\n",
    "format = '%Y-%m-%d %H:%M:%S'\n",
    "end_date = datetime.strptime(str(df_train.tail(1).index[0]), format)\n",
    "for i in [1]:#,2,4,7]:\n",
    "    start_date = end_date-timedelta(days=i)\n",
    "    x_train = df_train[(df_train.index > start_date) & (df_train.index < end_date)]\n",
    "    scalar = MinMaxScaler()\n",
    "    scalar.fit(x_train)\n",
    "    x_train = scalar.transform(x_train)\n",
    "    \n",
    "    regressor_keras = KerasRegressor(create_autoencoder_model2, verbose=0)\n",
    "    pipeline_keras = Pipeline([('model', regressor_keras)])\n",
    "    param_grid_keras ={\n",
    "            'model__epochs': [100, 200],\n",
    "            'model__batch_size': [256, 128],\n",
    "            'model__layer1':[50 ,40,30],\n",
    "            'model__layer2':[40,30, 20],\n",
    "            'model__encoding_dim':[30, 20, 10, 5]\n",
    "            }\n",
    "\n",
    "\n",
    "    gds_keras = GridSearchCV(\n",
    "            pipeline_keras,\n",
    "            param_grid=param_grid_keras,\n",
    "            scoring='neg_mean_squared_error',\n",
    "            cv=2, \n",
    "            refit=True,\n",
    "            verbose=2, n_jobs = 1\n",
    "        )\n",
    "    gds_keras.fit(x_train, x_train)\n",
    "\n",
    "    best_params = gds_keras.best_params_\n",
    "    df = pd.DataFrame({'file':[i],'model':['AE'], 'Hyperparameters':[gds_keras.best_params_]})\n",
    "    print(df)\n",
    "    if i==2:\n",
    "        df.to_csv('/mnt/stud/home/vpulagura/experiment/OpenDatasets/SWaT/AE_HYP.csv')\n",
    "    else:\n",
    "        df.to_csv('/mnt/stud/home/vpulagura/experiment/OpenDatasets/SWaT/AE_HYP.csv', mode='a', header=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "799209b20b2b97cb7d521719e25d3ce7f86c9d675fdfb18aaaa1ffc1f301c415"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
