{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-23 13:48:08.965657: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-06-23 13:48:08.965705: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold, KFold\n",
    "from sklearn import linear_model, metrics, preprocessing\n",
    "from math import sqrt, floor\n",
    "from datetime import datetime, timedelta\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, BatchNormalization, Input, LSTM,Dense,RepeatVector, TimeDistributed , LeakyReLU\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, IsolationForest\n",
    "from sklearn.metrics import r2_score, make_scorer, accuracy_score, mean_squared_error, mean_absolute_error\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl\n",
    "import tensorflow as tf\n",
    "LeakyReLU = LeakyReLU(alpha=0.1)\n",
    "import warnings\n",
    "import pandas as pd\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "import time\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "import math\n",
    "from sklearn.decomposition import PCA\n",
    "from numpy import array\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import keras\n",
    "from keras.layers import Dense, Dropout, Activation, BatchNormalization, Input,Conv2D, Conv1D, Conv1DTranspose,MaxPooling1D\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras import optimizers, Sequential\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from statistics import mean\n",
    "from sklearn.metrics import f1_score\n",
    "import pickle\n",
    "from keras.layers import Attention, GlobalMaxPooling1D\n",
    "from tensorflow.keras.layers import Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "0\n",
      "2019-10-11 08:24:20 2019-08-28 08:24:20 2019-09-11 08:24:20 2019-11-10 08:24:20\n",
      "(14406, 137) (2761, 137) (11645, 137)\n",
      "(2761, 137)\n",
      "{'model__batch_size': 256, 'model__epochs': 100, 'model__layer1': 64, 'model__layer2': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-30 23:32:40.575137: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-08-30 23:32:40.575325: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-08-30 23:32:40.575428: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-08-30 23:32:40.575554: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2023-08-30 23:32:40.623200: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-08-30 23:32:40.623364: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-08-30 23:32:40.623399: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-08-30 23:32:40.624690: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2019-04-02 15:20:48 2019-02-17 15:20:48 2019-03-03 15:20:48 2019-05-02 15:20:48\n",
      "(14115, 137) (2884, 137) (11231, 137)\n",
      "(2884, 137)\n",
      "{'model__batch_size': 256, 'model__epochs': 200, 'model__layer1': 128, 'model__layer2': 64}\n",
      "Epoch 00152: early stopping\n",
      "2\n",
      "2018-12-28 09:46:38 2018-11-14 09:46:38 2018-11-28 09:46:38 2019-01-27 09:46:38\n",
      "(14142, 137) (2884, 137) (11258, 137)\n",
      "(2884, 137)\n",
      "{'model__batch_size': 128, 'model__epochs': 100, 'model__layer1': 64, 'model__layer2': 32}\n",
      "3\n",
      "2018-10-13 16:26:39 2018-08-30 16:26:39 2018-09-13 16:26:39 2018-11-12 16:26:39\n",
      "(13338, 137) (2199, 137) (11139, 137)\n",
      "(2199, 137)\n",
      "{'model__batch_size': 256, 'model__epochs': 100, 'model__layer1': 128, 'model__layer2': 32}\n",
      "4\n",
      "2018-10-13 13:18:07 2018-08-30 13:18:07 2018-09-13 13:18:07 2018-11-12 13:18:07\n",
      "(13150, 137) (2225, 137) (10925, 137)\n",
      "(2225, 137)\n",
      "{'model__batch_size': 128, 'model__epochs': 100, 'model__layer1': 64, 'model__layer2': 32}\n",
      "5\n",
      "2019-05-19 09:01:02 2019-04-05 09:01:02 2019-04-19 09:01:02 2019-06-18 09:01:02\n",
      "(15044, 137) (2763, 137) (12281, 137)\n",
      "(2763, 137)\n",
      "{'model__batch_size': 256, 'model__epochs': 100, 'model__layer1': 64, 'model__layer2': 32}\n",
      "6\n",
      "2018-06-12 10:55:50 2018-04-29 10:55:50 2018-05-13 10:55:50 2018-07-12 10:55:50\n",
      "(13520, 137) (2655, 137) (10865, 137)\n",
      "(2655, 137)\n",
      "{'model__batch_size': 128, 'model__epochs': 100, 'model__layer1': 128, 'model__layer2': 32}\n",
      "7\n",
      "2019-05-27 04:57:13 2019-04-13 04:57:13 2019-04-27 04:57:13 2019-06-26 04:57:13\n",
      "(15203, 137) (2884, 137) (12319, 137)\n",
      "(2884, 137)\n",
      "{'model__batch_size': 128, 'model__epochs': 100, 'model__layer1': 64, 'model__layer2': 32}\n",
      "8\n",
      "2019-09-21 15:53:48 2019-08-08 15:53:48 2019-08-22 15:53:48 2019-10-21 15:53:48\n",
      "(11485, 137) (2884, 137) (8601, 137)\n",
      "(2884, 137)\n",
      "{'model__batch_size': 128, 'model__epochs': 100, 'model__layer1': 64, 'model__layer2': 32}\n",
      "9\n",
      "2020-01-19 07:22:19 2019-12-06 07:22:19 2019-12-20 07:22:19 2020-02-18 07:22:19\n",
      "(15030, 137) (2884, 137) (12146, 137)\n",
      "(2884, 137)\n",
      "{'model__batch_size': 256, 'model__epochs': 100, 'model__layer1': 128, 'model__layer2': 32}\n",
      "10\n",
      "2019-04-10 12:17:11 2019-02-25 12:17:11 2019-03-11 12:17:11 2019-05-10 12:17:11\n",
      "(14737, 137) (2884, 137) (11853, 137)\n",
      "(2884, 137)\n",
      "{'model__batch_size': 128, 'model__epochs': 200, 'model__layer1': 128, 'model__layer2': 64}\n",
      "Epoch 00121: early stopping\n",
      "11\n",
      "2019-08-18 12:36:11 2019-07-05 12:36:11 2019-07-19 12:36:11 2019-09-17 12:36:11\n",
      "(14636, 137) (2884, 137) (11752, 137)\n",
      "(2884, 137)\n",
      "{'model__batch_size': 128, 'model__epochs': 200, 'model__layer1': 128, 'model__layer2': 64}\n",
      "Epoch 00139: early stopping\n",
      "12\n",
      "2019-08-24 13:13:44 2019-07-11 13:13:44 2019-07-25 13:13:44 2019-09-23 13:13:44\n",
      "(14910, 137) (2674, 137) (12236, 137)\n",
      "(2674, 137)\n",
      "{'model__batch_size': 256, 'model__epochs': 200, 'model__layer1': 128, 'model__layer2': 32}\n",
      "Epoch 00135: early stopping\n",
      "13\n",
      "2019-11-05 11:51:23 2019-09-22 11:51:23 2019-10-06 11:51:23 2019-12-05 11:51:23\n",
      "(15006, 137) (2884, 137) (12122, 137)\n",
      "(2884, 137)\n",
      "{'model__batch_size': 128, 'model__epochs': 100, 'model__layer1': 128, 'model__layer2': 32}\n",
      "14\n",
      "2019-10-12 15:00:20 2019-08-29 15:00:20 2019-09-12 15:00:20 2019-11-11 15:00:20\n",
      "(15223, 137) (2884, 137) (12339, 137)\n",
      "(2884, 137)\n",
      "{'model__batch_size': 128, 'model__epochs': 200, 'model__layer1': 128, 'model__layer2': 32}\n",
      "Epoch 00162: early stopping\n",
      "15\n",
      "2019-10-13 09:51:49 2019-08-30 09:51:49 2019-09-13 09:51:49 2019-11-12 09:51:49\n",
      "(15217, 137) (2884, 137) (12333, 137)\n",
      "(2884, 137)\n",
      "{'model__batch_size': 128, 'model__epochs': 100, 'model__layer1': 64, 'model__layer2': 32}\n",
      "16\n",
      "2019-10-26 08:15:14 2019-09-12 08:15:14 2019-09-26 08:15:14 2019-11-25 08:15:14\n",
      "(15224, 137) (2884, 137) (12340, 137)\n",
      "(2884, 137)\n",
      "{'model__batch_size': 128, 'model__epochs': 100, 'model__layer1': 128, 'model__layer2': 32}\n",
      "17\n",
      "2019-10-18 07:26:00 2019-09-04 07:26:00 2019-09-18 07:26:00 2019-11-17 07:26:00\n",
      "(15223, 137) (2884, 137) (12339, 137)\n",
      "(2884, 137)\n",
      "{'model__batch_size': 128, 'model__epochs': 100, 'model__layer1': 128, 'model__layer2': 32}\n",
      "18\n",
      "2020-05-23 13:56:28 2020-04-09 13:56:28 2020-04-23 13:56:28 2020-06-22 13:56:28\n",
      "(15194, 137) (2884, 137) (12310, 137)\n",
      "(2884, 137)\n",
      "{'model__batch_size': 128, 'model__epochs': 200, 'model__layer1': 128, 'model__layer2': 32}\n",
      "Epoch 00103: early stopping\n",
      "[0.27006702632009155, 0.20091970286522817, 0.5683407501589319, 0.7452935789152336, 0.5362994857074513, 0.5724478594950604, 0.0729312762973352, 0.5792284866468842, 0.963401882188916, 0.9174957534578986, 0.09586140519730511, 0.8904002501563477, 0.7844139252634941, 0.482387361029842, 0.28587015821058376, 0.024339360222531293, 0.008931419457735247, 0.024758454106280196, 0.608877928483354]\n",
      "30\n",
      "0\n",
      "2019-10-11 08:24:20 2019-08-12 08:24:20 2019-09-11 08:24:20 2019-11-10 08:24:20\n",
      "(17702, 137) (6057, 137) (11645, 137)\n",
      "(6057, 137)\n",
      "{'model__batch_size': 128, 'model__epochs': 100, 'model__layer1': 128, 'model__layer2': 32, 'model__lr': 0.001}\n",
      "1\n",
      "2019-04-02 15:20:48 2019-02-01 15:20:48 2019-03-03 15:20:48 2019-05-02 15:20:48\n",
      "(17293, 137) (6062, 137) (11231, 137)\n",
      "(6062, 137)\n",
      "{'model__batch_size': 128, 'model__epochs': 100, 'model__layer1': 64, 'model__layer2': 64, 'model__lr': 0.01}\n",
      "2\n",
      "2018-12-28 09:46:38 2018-10-29 09:46:38 2018-11-28 09:46:38 2019-01-27 09:46:38\n",
      "(17438, 137) (6180, 137) (11258, 137)\n",
      "(6180, 137)\n",
      "{'model__batch_size': 256, 'model__epochs': 100, 'model__layer1': 64, 'model__layer2': 64, 'model__lr': 0.01}\n",
      "3\n",
      "2018-10-13 16:26:39 2018-08-14 16:26:39 2018-09-13 16:26:39 2018-11-12 16:26:39\n",
      "(16629, 137) (5490, 137) (11139, 137)\n",
      "(5490, 137)\n",
      "{'model__batch_size': 256, 'model__epochs': 100, 'model__layer1': 64, 'model__layer2': 16, 'model__lr': 0.001}\n",
      "4\n",
      "2018-10-13 13:18:07 2018-08-14 13:18:07 2018-09-13 13:18:07 2018-11-12 13:18:07\n",
      "(16441, 137) (5516, 137) (10925, 137)\n",
      "(5516, 137)\n",
      "{'model__batch_size': 256, 'model__epochs': 100, 'model__layer1': 64, 'model__layer2': 64, 'model__lr': 0.01}\n",
      "5\n",
      "2019-05-19 09:01:02 2019-03-20 09:01:02 2019-04-19 09:01:02 2019-06-18 09:01:02\n",
      "(18261, 137) (5980, 137) (12281, 137)\n",
      "(5980, 137)\n",
      "{'model__batch_size': 128, 'model__epochs': 100, 'model__layer1': 128, 'model__layer2': 64, 'model__lr': 0.001}\n",
      "6\n",
      "2018-06-12 10:55:50 2018-04-13 10:55:50 2018-05-13 10:55:50 2018-07-12 10:55:50\n",
      "(16788, 137) (5923, 137) (10865, 137)\n",
      "(5923, 137)\n",
      "{'model__batch_size': 128, 'model__epochs': 200, 'model__layer1': 128, 'model__layer2': 64, 'model__lr': 0.01}\n",
      "Epoch 00108: early stopping\n",
      "7\n",
      "2019-05-27 04:57:13 2019-03-28 04:57:13 2019-04-27 04:57:13 2019-06-26 04:57:13\n",
      "(18499, 137) (6180, 137) (12319, 137)\n",
      "(6180, 137)\n",
      "{'model__batch_size': 256, 'model__epochs': 100, 'model__layer1': 64, 'model__layer2': 64, 'model__lr': 0.01}\n",
      "8\n",
      "2019-09-21 15:53:48 2019-07-23 15:53:48 2019-08-22 15:53:48 2019-10-21 15:53:48\n",
      "(14781, 137) (6180, 137) (8601, 137)\n",
      "(6180, 137)\n",
      "{'model__batch_size': 256, 'model__epochs': 100, 'model__layer1': 128, 'model__layer2': 64, 'model__lr': 0.01}\n",
      "9\n",
      "2020-01-19 07:22:19 2019-11-20 07:22:19 2019-12-20 07:22:19 2020-02-18 07:22:19\n",
      "(18326, 137) (6180, 137) (12146, 137)\n",
      "(6180, 137)\n",
      "{'model__batch_size': 256, 'model__epochs': 100, 'model__layer1': 128, 'model__layer2': 16, 'model__lr': 0.001}\n",
      "10\n",
      "2019-04-10 12:17:11 2019-02-09 12:17:11 2019-03-11 12:17:11 2019-05-10 12:17:11\n",
      "(18018, 137) (6165, 137) (11853, 137)\n",
      "(6165, 137)\n",
      "{'model__batch_size': 256, 'model__epochs': 100, 'model__layer1': 64, 'model__layer2': 64, 'model__lr': 0.001}\n",
      "11\n",
      "2019-08-18 12:36:11 2019-06-19 12:36:11 2019-07-19 12:36:11 2019-09-17 12:36:11\n",
      "(17928, 137) (6176, 137) (11752, 137)\n",
      "(6176, 137)\n",
      "{'model__batch_size': 256, 'model__epochs': 200, 'model__layer1': 128, 'model__layer2': 16, 'model__lr': 0.001}\n",
      "12\n",
      "2019-08-24 13:13:44 2019-06-25 13:13:44 2019-07-25 13:13:44 2019-09-23 13:13:44\n",
      "(17977, 137) (5741, 137) (12236, 137)\n",
      "(5741, 137)\n",
      "{'model__batch_size': 128, 'model__epochs': 100, 'model__layer1': 128, 'model__layer2': 16, 'model__lr': 0.01}\n",
      "13\n",
      "2019-11-05 11:51:23 2019-09-06 11:51:23 2019-10-06 11:51:23 2019-12-05 11:51:23\n",
      "(18302, 137) (6180, 137) (12122, 137)\n",
      "(6180, 137)\n",
      "{'model__batch_size': 128, 'model__epochs': 200, 'model__layer1': 64, 'model__layer2': 16, 'model__lr': 0.01}\n",
      "14\n",
      "2019-10-12 15:00:20 2019-08-13 15:00:20 2019-09-12 15:00:20 2019-11-11 15:00:20\n",
      "(18498, 137) (6159, 137) (12339, 137)\n",
      "(6159, 137)\n",
      "{'model__batch_size': 256, 'model__epochs': 200, 'model__layer1': 128, 'model__layer2': 16, 'model__lr': 0.001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "2019-10-13 09:51:49 2019-08-14 09:51:49 2019-09-13 09:51:49 2019-11-12 09:51:49\n",
      "(18495, 137) (6162, 137) (12333, 137)\n",
      "(6162, 137)\n",
      "{'model__batch_size': 256, 'model__epochs': 200, 'model__layer1': 64, 'model__layer2': 16, 'model__lr': 0.001}\n",
      "16\n",
      "2019-10-26 08:15:14 2019-08-27 08:15:14 2019-09-26 08:15:14 2019-11-25 08:15:14\n",
      "(18520, 137) (6180, 137) (12340, 137)\n",
      "(6180, 137)\n",
      "{'model__batch_size': 256, 'model__epochs': 200, 'model__layer1': 64, 'model__layer2': 64, 'model__lr': 0.01}\n",
      "Epoch 00138: early stopping\n",
      "17\n",
      "2019-10-18 07:26:00 2019-08-19 07:26:00 2019-09-18 07:26:00 2019-11-17 07:26:00\n",
      "(18519, 137) (6180, 137) (12339, 137)\n",
      "(6180, 137)\n",
      "{'model__batch_size': 256, 'model__epochs': 100, 'model__layer1': 128, 'model__layer2': 64, 'model__lr': 0.01}\n",
      "18\n",
      "2020-05-23 13:56:28 2020-03-24 13:56:28 2020-04-23 13:56:28 2020-06-22 13:56:28\n",
      "(18490, 137) (6180, 137) (12310, 137)\n",
      "(6180, 137)\n",
      "{'model__batch_size': 256, 'model__epochs': 100, 'model__layer1': 64, 'model__layer2': 64, 'model__lr': 0.001}\n",
      "[0.9711255156157926, 0.2016687377951358, 0.9775465498357064, 0.7503329576887614, 0.5362994857074513, 0.9938065745593139, 0.7643979057591622, 0.9625246548323472, 0.9913854989231873, 0.9235466536394724, 0.8613445378151261, 0.9956278419027632, 0.9108445653517993, 0.5958369470945359, 0.9479873360470376, 0.673076923076923, 0.012037833190025797, 0.03767441860465116, 0.9915662650602409]\n",
      "90\n",
      "0\n",
      "2019-10-11 08:24:20 2019-06-13 08:24:20 2019-09-11 08:24:20 2019-11-10 08:24:20\n",
      "(30062, 137) (18417, 137) (11645, 137)\n",
      "(18417, 137)\n",
      "{'model__batch_size': 128, 'model__epochs': 100, 'model__layer1': 64, 'model__layer2': 16, 'model__lr': 0.001}\n",
      "1\n",
      "2019-04-02 15:20:48 2018-12-03 15:20:48 2019-03-03 15:20:48 2019-05-02 15:20:48\n",
      "(28024, 137) (16793, 137) (11231, 137)\n",
      "(16793, 137)\n",
      "{'model__batch_size': 256, 'model__epochs': 100, 'model__layer1': 128, 'model__layer2': 32, 'model__lr': 0.01}\n",
      "2\n",
      "2018-12-28 09:46:38 2018-08-30 09:46:38 2018-11-28 09:46:38 2019-01-27 09:46:38\n",
      "(29714, 137) (18456, 137) (11258, 137)\n",
      "(18456, 137)\n",
      "{'model__batch_size': 256, 'model__epochs': 100, 'model__layer1': 64, 'model__layer2': 16, 'model__lr': 0.001}\n",
      "Epoch 00085: early stopping\n",
      "3\n",
      "2018-10-13 16:26:39 2018-06-15 16:26:39 2018-09-13 16:26:39 2018-11-12 16:26:39\n",
      "(28080, 137) (16941, 137) (11139, 137)\n",
      "(16941, 137)\n",
      "{'model__batch_size': 128, 'model__epochs': 200, 'model__layer1': 64, 'model__layer2': 64, 'model__lr': 0.01}\n",
      "Epoch 00107: early stopping\n",
      "4\n",
      "2018-10-13 13:18:07 2018-06-15 13:18:07 2018-09-13 13:18:07 2018-11-12 13:18:07\n",
      "(28575, 137) (17650, 137) (10925, 137)\n",
      "(17650, 137)\n",
      "{'model__batch_size': 128, 'model__epochs': 200, 'model__layer1': 64, 'model__layer2': 64, 'model__lr': 0.01}\n",
      "Epoch 00144: early stopping\n",
      "5\n",
      "2019-05-19 09:01:02 2019-01-19 09:01:02 2019-04-19 09:01:02 2019-06-18 09:01:02\n",
      "(29940, 137) (17659, 137) (12281, 137)\n",
      "(17659, 137)\n",
      "{'model__batch_size': 128, 'model__epochs': 200, 'model__layer1': 64, 'model__layer2': 32, 'model__lr': 0.01}\n",
      "Epoch 00106: early stopping\n",
      "6\n",
      "2018-06-12 10:55:50 2018-02-12 10:55:50 2018-05-13 10:55:50 2018-07-12 10:55:50\n",
      "(29018, 137) (18153, 137) (10865, 137)\n",
      "(18153, 137)\n",
      "{'model__batch_size': 128, 'model__epochs': 100, 'model__layer1': 128, 'model__layer2': 64, 'model__lr': 0.01}\n",
      "Epoch 00048: early stopping\n",
      "7\n",
      "2019-05-27 04:57:13 2019-01-27 04:57:13 2019-04-27 04:57:13 2019-06-26 04:57:13\n",
      "(30829, 137) (18510, 137) (12319, 137)\n",
      "(18510, 137)\n",
      "{'model__batch_size': 128, 'model__epochs': 200, 'model__layer1': 128, 'model__layer2': 32, 'model__lr': 0.001}\n",
      "Epoch 00094: early stopping\n",
      "8\n",
      "2019-09-21 15:53:48 2019-05-24 15:53:48 2019-08-22 15:53:48 2019-10-21 15:53:48\n",
      "(27102, 137) (18501, 137) (8601, 137)\n",
      "(18501, 137)\n",
      "{'model__batch_size': 256, 'model__epochs': 200, 'model__layer1': 128, 'model__layer2': 16, 'model__lr': 0.01}\n",
      "Epoch 00113: early stopping\n",
      "9\n",
      "2020-01-19 07:22:19 2019-09-21 07:22:19 2019-12-20 07:22:19 2020-02-18 07:22:19\n",
      "(30686, 137) (18540, 137) (12146, 137)\n",
      "(18540, 137)\n",
      "{'model__batch_size': 256, 'model__epochs': 100, 'model__layer1': 64, 'model__layer2': 16, 'model__lr': 0.001}\n",
      "10\n",
      "2019-04-10 12:17:11 2018-12-11 12:17:11 2019-03-11 12:17:11 2019-05-10 12:17:11\n",
      "(30378, 137) (18525, 137) (11853, 137)\n",
      "(18525, 137)\n",
      "{'model__batch_size': 128, 'model__epochs': 100, 'model__layer1': 64, 'model__layer2': 32, 'model__lr': 0.001}\n",
      "11\n",
      "2019-08-18 12:36:11 2019-04-20 12:36:11 2019-07-19 12:36:11 2019-09-17 12:36:11\n",
      "(29930, 137) (18178, 137) (11752, 137)\n",
      "(18178, 137)\n",
      "{'model__batch_size': 128, 'model__epochs': 100, 'model__layer1': 64, 'model__layer2': 16, 'model__lr': 0.01}\n",
      "12\n",
      "2019-08-24 13:13:44 2019-04-26 13:13:44 2019-07-25 13:13:44 2019-09-23 13:13:44\n",
      "(28151, 137) (15915, 137) (12236, 137)\n",
      "(15915, 137)\n",
      "{'model__batch_size': 256, 'model__epochs': 100, 'model__layer1': 128, 'model__layer2': 32, 'model__lr': 0.01}\n",
      "13\n",
      "2019-11-05 11:51:23 2019-07-08 11:51:23 2019-10-06 11:51:23 2019-12-05 11:51:23\n",
      "(30662, 137) (18540, 137) (12122, 137)\n",
      "(18540, 137)\n",
      "{'model__batch_size': 256, 'model__epochs': 100, 'model__layer1': 64, 'model__layer2': 16, 'model__lr': 0.01}\n",
      "14\n",
      "2019-10-12 15:00:20 2019-06-14 15:00:20 2019-09-12 15:00:20 2019-11-11 15:00:20\n",
      "(30278, 137) (17939, 137) (12339, 137)\n",
      "(17939, 137)\n",
      "{'model__batch_size': 128, 'model__epochs': 100, 'model__layer1': 64, 'model__layer2': 32, 'model__lr': 0.01}\n",
      "Epoch 00096: early stopping\n",
      "15\n",
      "2019-10-13 09:51:49 2019-06-15 09:51:49 2019-09-13 09:51:49 2019-11-12 09:51:49\n",
      "(30725, 137) (18392, 137) (12333, 137)\n",
      "(18392, 137)\n",
      "{'model__batch_size': 128, 'model__epochs': 200, 'model__layer1': 64, 'model__layer2': 32, 'model__lr': 0.001}\n",
      "Epoch 00099: early stopping\n",
      "16\n",
      "2019-10-26 08:15:14 2019-06-28 08:15:14 2019-09-26 08:15:14 2019-11-25 08:15:14\n",
      "(30765, 137) (18425, 137) (12340, 137)\n",
      "(18425, 137)\n",
      "{'model__batch_size': 128, 'model__epochs': 100, 'model__layer1': 64, 'model__layer2': 64, 'model__lr': 0.001}\n",
      "Epoch 00085: early stopping\n",
      "17\n",
      "2019-10-18 07:26:00 2019-06-20 07:26:00 2019-09-18 07:26:00 2019-11-17 07:26:00\n",
      "(30278, 137) (17939, 137) (12339, 137)\n",
      "(17939, 137)\n",
      "{'model__batch_size': 128, 'model__epochs': 100, 'model__layer1': 128, 'model__layer2': 64, 'model__lr': 0.001}\n",
      "Epoch 00053: early stopping\n",
      "18\n",
      "2020-05-23 13:56:28 2020-01-24 13:56:28 2020-04-23 13:56:28 2020-06-22 13:56:28\n",
      "(30843, 137) (18533, 137) (12310, 137)\n",
      "(18533, 137)\n",
      "{'model__batch_size': 256, 'model__epochs': 100, 'model__layer1': 128, 'model__layer2': 64, 'model__lr': 0.001}\n",
      "[0.9933694996986135, 0.20188377465789942, 0.019933554817275746, 0.7484925907000511, 0.9521581968955987, 0.9957040572792363, 0.7578947368421053, 0.9779559118236473, 0.9963846710050615, 0.9620382165605095, 0.8680851063829788, 0.9837702871410737, 0.998779661016949, 0.9939686369119421, 0.9914285714285714, 0.6336633663366337, 0.742857142857143, 0.7624309392265194, 0.9985844287158746]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold, KFold\n",
    "from sklearn import linear_model, metrics, preprocessing\n",
    "from math import sqrt, floor\n",
    "from datetime import datetime, timedelta\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, BatchNormalization, Input, LSTM,Dense,RepeatVector, TimeDistributed , LeakyReLU\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, IsolationForest\n",
    "from sklearn.metrics import r2_score, make_scorer, accuracy_score, mean_squared_error, mean_absolute_error\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl\n",
    "import tensorflow as tf\n",
    "LeakyReLU = LeakyReLU(alpha=0.1)\n",
    "import warnings\n",
    "import pandas as pd\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "import time\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "import math\n",
    "from sklearn.decomposition import PCA\n",
    "from numpy import array\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import keras\n",
    "from keras.layers import Dense, Dropout, Activation, BatchNormalization, Input,Conv2D, Conv1D, Conv1DTranspose,MaxPooling1D\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras import optimizers, Sequential\n",
    "from sklearn.metrics import f1_score\n",
    "import pickle\n",
    "import ast\n",
    "from keras.layers import Attention, GlobalMaxPooling1D\n",
    "from tensorflow.keras.layers import Reshape\n",
    "\n",
    "\n",
    "path_errors = 'datapath'\n",
    "path_features = 'datapath'\n",
    "df_errors = pd.read_csv(path_errors)\n",
    "df_features = pd.read_csv(path_features)\n",
    "total_features = list(df_features[(df_features['True/False'] == 'TRUE') | (df_features['True/False'] == 'NotAvailable')]['Features'])\n",
    "tot_feat = pd.read_csv('datapath')\n",
    "tot_feat = list(tot_feat['feat'])\n",
    "\n",
    "def create_directory(directory_path):\n",
    "    if not os.path.exists(directory_path):\n",
    "        os.makedirs(directory_path)\n",
    "\n",
    "def flatten(X):\n",
    "    flattened_X = np.empty((X.shape[0], X.shape[2]))  # sample x features array.\n",
    "    for i in range(X.shape[0]):\n",
    "        flattened_X[i] = X[i, (X.shape[1]-1), :]\n",
    "    return(flattened_X)\n",
    "def temporalize(X, lookback=8):\n",
    "\n",
    "    output_X = []\n",
    "    for i in range(len(X) - lookback - 1):\n",
    "        t = []\n",
    "        for j in range(1, lookback + 1):\n",
    "            t.append(X[[(i + j + 1)], :])\n",
    "        output_X.append(t)\n",
    "    return np.squeeze(np.array(output_X))\n",
    "\n",
    "\n",
    "def create_lstm_attn_autoencoder_model(layer1=20, layer2=4, lr=0.005):\n",
    "    encoder_inputs = Input(shape=(8, 137))\n",
    "    encoder = LSTM(layer1, activation='relu', return_sequences=True)(encoder_inputs)\n",
    "    encoder = LSTM(layer2, activation='relu', return_sequences=False)(encoder)\n",
    "    encoder_outputs = RepeatVector(8)(encoder)\n",
    "    attention = Attention()([encoder, encoder_outputs])\n",
    "    attention = GlobalMaxPooling1D()(attention)\n",
    "    attention = Reshape((1, layer2))(attention)\n",
    "    decoder = LSTM(layer2, activation='relu', return_sequences=True)(attention)\n",
    "    decoder = LSTM(layer1, activation='relu', return_sequences=True)(decoder)\n",
    "    decoder_outputs = TimeDistributed(Dense(137))(decoder)\n",
    "    autoencoder = Model(encoder_inputs, decoder_outputs)\n",
    "    autoencoder.compile(optimizer='adam', loss='mse')\n",
    "    return autoencoder\n",
    "\n",
    "def getHyperParams(file, df_hyp):\n",
    "    param_dict = ast.literal_eval(df_hyp.loc[df_hyp['Inverter'] == file]['Feature Importance'].values[0])\n",
    "    print(param_dict)\n",
    "    return param_dict['model__batch_size'], param_dict['model__epochs'],param_dict['model__layer1'], param_dict['model__layer2']\n",
    "\n",
    "callback1 = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10, verbose=1)\n",
    "dayWiseResultsTest = {}\n",
    "dayWiseResultsTrain = {}\n",
    "lookback = 8\n",
    "for itr in range(3,4):\n",
    "    RESULTS_PATH_TRAIN = f'datapath'\n",
    "    RESULTS_PATH_TEST = f'datapath'\n",
    "    for dayStart in [14, 30, 90]:\n",
    "        hyp = '2W' if dayStart == 14 else '1M' if dayStart == 30 else '3M' \n",
    "        df_hyp = pd.read_csv(f\"datapath/LstmAttnAE{hyp}.csv\")\n",
    "        print(dayStart)\n",
    "        daysrange = str(dayStart)\n",
    "        source_dict_results = {}\n",
    "        source_dict_results_train = {}\n",
    "        lst=[]\n",
    "        for i in range(19):\n",
    "            tot_feat.append('ErrBits')\n",
    "            print(i)\n",
    "            inverter = i\n",
    "            df_inv_0 = pd.read_csv(f'datapath/{inverter}.csv')\n",
    "            df_inv_0['Timestamp'] = pd.to_datetime(df_inv_0['Timestamp'])\n",
    "            df_inv_0.sort_values(by='Timestamp', inplace=True)\n",
    "            df_inv_0 = df_inv_0.set_index(df_inv_0['Timestamp'])\n",
    "\n",
    "            format = '%Y-%m-%d %H:%M:%S'\n",
    "            error_date = datetime.strptime(df_errors[(df_errors['Inverter'] == inverter) & (df_errors['had_failure'] == True)]['failure_time'].values[0][0:19], format)\n",
    "            start_days = 30+dayStart\n",
    "            start_date = error_date-timedelta(days= start_days)\n",
    "            end_date = error_date+timedelta(days= 1*30)\n",
    "            split_date = error_date-timedelta(days= 1*30)\n",
    "            df_inv_0 = df_inv_0[(df_inv_0.index >= start_date) & (df_inv_0.index < end_date)]\n",
    "            df_inv_0 = pd.get_dummies(df_inv_0)\n",
    "\n",
    "            for feat in tot_feat:\n",
    "                if feat not in df_inv_0.columns:\n",
    "                    df_inv_0[feat] = 0\n",
    "            df_inv_0 = df_inv_0[tot_feat]\n",
    "            df_inv_0 = df_inv_0.dropna()\n",
    "\n",
    "            df_target = df_inv_0[['ErrBits']]\n",
    "            tot_feat.remove('ErrBits')\n",
    "            df_inv_0 = df_inv_0[tot_feat]\n",
    "\n",
    "            Xtrain_0, Xtest_0 = df_inv_0[(df_inv_0.index >= start_date) & (df_inv_0.index< split_date)], df_inv_0[(df_inv_0.index >= split_date) & (df_inv_0.index< end_date)]\n",
    "            print(error_date, start_date, split_date, end_date)\n",
    "            print(df_inv_0.shape, Xtrain_0.shape, Xtest_0.shape)\n",
    "            Timestamp_train_0, Timestamp_test_0 = df_inv_0[(df_inv_0.index >= start_date) & (df_inv_0.index< split_date)].index, df_inv_0[(df_inv_0.index >= split_date) & (df_inv_0.index< end_date)].index\n",
    "            ytrain, ytest = df_target[(df_target.index >= start_date) & (df_target.index< split_date)], df_target[(df_target.index >= split_date) & (df_target.index< end_date)]\n",
    "            ytrain, ytest = ytrain[lookback+1:], ytest[lookback+1:]\n",
    "            print(Xtrain_0.shape)\n",
    "            if Xtrain_0.shape[0]>1:\n",
    "                X_scaler = MinMaxScaler()\n",
    "                X_scaler.fit(Xtrain_0)\n",
    "                xtrain = X_scaler.transform(Xtrain_0)\n",
    "                xtest = X_scaler.transform(Xtest_0)\n",
    "                xtrain = temporalize(xtrain)\n",
    "                xtest = temporalize(xtest)\n",
    "                model__batch_size, model__epochs, model__layer1, model__layer2 = getHyperParams(inverter, df_hyp)\n",
    "                model  = create_lstm_attn_autoencoder_model(layer1=model__layer1, layer2=model__layer2)\n",
    "                model.fit(xtrain, xtrain, epochs=model__epochs, batch_size=model__batch_size, verbose=False,validation_split=0.1, callbacks=callback1)\n",
    "                test_enc = model.predict(xtest)\n",
    "                train_enc = model.predict(xtrain)\n",
    "                test_mses = np.mean(np.power(flatten(xtest)- flatten(test_enc), 2), axis=1)\n",
    "                train_mses = np.mean(np.power(flatten(xtrain)- flatten(train_enc), 2), axis=1)\n",
    "                test_maes = np.mean(flatten(xtest)- flatten(test_enc), axis=1)\n",
    "                train_maes = np.mean(flatten(xtrain)- flatten(train_enc), axis=1)\n",
    "\n",
    "                mse_threshold = np.max(train_mses)\n",
    "                mae_threshold = np.max(train_maes)\n",
    "\n",
    "                ypred_mse = np.where(test_mses>mse_threshold,1,0)\n",
    "                ypred_mae = np.where(test_maes>mae_threshold,1,0)\n",
    "\n",
    "\n",
    "                test_df = pd.DataFrame(ytest)\n",
    "                test_df['mse_scores'] = test_mses\n",
    "                test_df['ytrue'] = np.where(test_df['ErrBits']>0, 1, 0)\n",
    "                test_df['mae_scores'] = test_maes\n",
    "                test_df['ypred_mse'] = ypred_mse\n",
    "                test_df['ypred_mae'] = ypred_mae\n",
    "                lst.append(f1_score(y_true=test_df['ytrue'], y_pred=test_df['ypred_mse']))\n",
    "                test_df = test_df[['ytrue','ypred_mse','ypred_mae','mse_scores', 'mae_scores']]\n",
    "                source_dict_results[f'inv_{i}'] = test_df\n",
    "                \n",
    "                train_df = pd.DataFrame(ytrain)\n",
    "                train_df['mse_scores'] = train_mses\n",
    "                train_df['ytrue'] = np.where(train_df['ErrBits']>0, 1, 0)\n",
    "                train_df['mae_scores'] = train_maes\n",
    "                train_df = train_df[['ytrue','mse_scores', 'mae_scores']]\n",
    "                source_dict_results_train[f'inv_{i}'] = train_df\n",
    "                \n",
    "        dayWiseResultsTest[dayStart] = source_dict_results \n",
    "        dayWiseResultsTrain[dayStart] = source_dict_results_train\n",
    "        print(lst)\n",
    "    with open(f'{RESULTS_PATH_TRAIN}/train_STL_LstmAttnAE.pkl', 'wb') as f:\n",
    "        pickle.dump(dayWiseResultsTrain, f) \n",
    "    with open(f'{RESULTS_PATH_TEST}/test_STL_LstmAttnAE.pkl', 'wb') as f:\n",
    "        pickle.dump(dayWiseResultsTest, f) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "799209b20b2b97cb7d521719e25d3ce7f86c9d675fdfb18aaaa1ffc1f301c415"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
